---
layout: post
title: Audio Programming 
cover-img: ["assets/img/posts/speaker.jpg"]
tags: [ðŸŽµmusic, ðŸ’»code]
---

This is a post about audio programming and what people of the field call DSP (digital signal processing). I just started a course and here is the place where I will be keeping my notes. 

what are the plugins in the industry? 
what projects can we do at the end?
I would like more resources to check (during the lesson, code and plugins).
I would like to use JUCE for my plugin at the end. I have to find my level. 
book a studio.


DONT FORGET: you don't learn music in unis. You learn it playing, on the street, breaking rules and enjoying it as much as possible. It's a hobby, not a work.

### Most important books / resources

The two most important ones:
* The Computer Music Tutorial (1997/2023) by Curtis Roads
* Audio Processes (2017) by David Creasey

Some other good resources from the lessons:
* Computer Music - Synthesis, Composition, and Performance (1997) by Charles Dodge and Thomas Jerse
* Designing Audio Effect Plugins (2013) in C++ by Will Pirkle

* [Distortion In The Studio](https://www.soundonsound.com/techniques/distortion-studio)
* [wiki on ](https://en.wikipedia.org/wiki/Distortion_(music)), [wiki on ](https://en.wikipedia.org/wiki/Filter_(signal_processing)), [wiki](https://en.wikipedia.org/wiki/Digital_filter), 
* RBJ book: 
* Psychoacoustic: auditory analysis


### around the internet

After I have gotten a grasp of the basic concepts (like reverb, amplitutde, filtering, tremolos, ...), I can go more deep into how people create sounds (and manipulate timbre).

Max/MSP/Jitter is a visual programming language for music and multimedia. People put layers and create controls and the parameters they can change. It's the product of company "Cycling 74".
Similar products are Reaktor, Kontakt programming, Synthmaker (Flowstone). Reaktor and Pigments are more easy and good out of the box. Gradually though to become a pro you have to switch to MaxMSP. Pure Data is a good FOSS alternative too.

Now it's integrated with the Ableton ecosystem. It's called "Max For Life" and you can create any kind of device/instrument/effect.


### GPT resources - books and websites

ðŸŽ¼ 1. Music & Synthesis Books
"The Computer Music Tutorial" â€“ Curtis Roads
ðŸ“– Covers detailed harmonic breakdowns of many instrument families.
"Musimathics: The Mathematical Foundations of Music" â€“ Gareth Loy
ðŸ“– Explores the physics of musical tones and harmonic relationships.
"Sound Synthesis and Sampling" â€“ Martin Russ
ðŸ“– Discusses different synthesis techniques, including additive.
ðŸ”¬ 2. Scientific Databases & Research Papers
ICASSP (IEEE International Conference on Acoustics, Speech, and Signal Processing)
https://ieeexplore.ieee.org/Xplore/home.jsp
Papers on spectral analysis of musical instruments.
Journal of the Acoustical Society of America (JASA)
https://asa.scitation.org/journal/jas
Research on instrument timbres and harmonic structures.
ðŸŽ›ï¸ 3. Online Additive Synthesis Resources
McGill University â€“ Musical Instrument Samples & Spectral Data
http://www.music.mcgill.ca/resources/mumt/
Includes spectral breakdowns of real instruments.
Ircam (Institute for Research and Coordination in Acoustics/Music)
https://www.ircam.fr/
Has additive synthesis studies and spectral data.
ðŸŽ¹ 4. Open-Source & Online Tools
University of Iowa Musical Instrument Samples (Spectral Analysis Data)
https://theremin.music.uiowa.edu/MIS.html
Contains high-quality harmonic breakdowns of real instruments.
Smartelectronix Harmonic Tables
http://www.smartelectronix.com/
A collection of harmonic content for various synth patches.
Online Spectrum Analyzers
Tools like Sonic Visualiser (https://www.sonicvisualiser.org/) allow you to analyze harmonics in recordings.
ðŸŽšï¸ 5. Synth Patches & Sound Design Forums
KVR Audio Forum â€“ https://www.kvraudio.com/forum/
Huge community discussing additive synthesis & sound recipes.
Synth Secrets (Sound on Sound Magazine) â€“ https://www.soundonsound.com/series/synth-secrets
Explains how to construct various sounds using synthesis.
Patch Storage â€“ https://patchstorage.com/
Community-driven patch repository for additive synths.
ðŸŽµ 6. Spectral Analysis of Real Instruments
If you want to analyze real instrument recordings, you can use:

Audacity (with Spectrum Analyzer Plugin)
Sonic Visualiser
Max/MSP or Pure Data (PD)
These tools let you extract harmonics from recordings and recreate them in your synth!


### Best synths of all time

[Link](https://www.desertislandcloud.com/2024/10/top-ten-synths-of-all-time/), [best synths of all time](https://youtu.be/pY-UiRNQCdE), [top 20 synths - sonicstate](https://youtu.be/fwCqVCeY5yI)

The ones that are quoted the most:
* Minimoog, Roland Jupiter-8, Yamaha DX-7, ARP 2600, Korg M1, Yamaha CS-80, Oberheim OB-8, Roland D-50, Sequential Circuits Prophet 5, Roland TB-303, Roland Juno 106

The list includes these icons:   
* Fairlight CMI, ARP Odyssey, Korg MS20, Roland JV-1080, Access Virus, Juno 60, Mellotron, The Proteus, Nord Lead, EMS VCS3, Roland SH-101, Solina, Roland TB-303 (acid house for the first time), Moog Subsequent 37, PPG Wave 2.2/3, Korg Wavestation


GPT answer (with categories and chronological ordering)

Analog Synths:
* Minimoog Model D (1970) â€“ The first portable synthesizer, used by artists like Kraftwerk, Parliament-Funkadelic, and Rick Wakeman.
* Roland Juno-106 (1984) â€“ A staple in electronic, synth-pop, and house music, loved for its lush pads and chorus effect.
* Roland Jupiter-8 (1981) â€“ A classic for rich, warm polyphonic sounds, used by artists like Duran Duran and Prince.
* ARP 2600 (1971) â€“ A semi-modular beast known for its punchy sounds, famously used by R2-D2 in Star Wars.
* Sequential Circuits Prophet-5 (1978) â€“ One of the first programmable polyphonic synths, heard in countless â€˜80s hits.
* Korg MS-20 (1978) â€“ A semi-modular synth known for its raw, aggressive sound and incredible filter.
Digital Synths:
* Yamaha DX7 (1983) â€“ Defined the sound of the â€˜80s with its bright FM synthesis, used in hits by Whitney Houston and A-ha.
* Roland D-50 (1987) â€“ Introduced â€œLinear Arithmeticâ€ synthesis, featured in hits by Jean-Michel Jarre and Enya.
* Korg M1 (1988) â€“ One of the best-selling synths ever, responsible for the iconic â€œhouse pianoâ€ sound.
Modern & Hybrid Synths:
* Nord Lead series (1995â€“present) â€“ A pioneer of virtual analog synthesis, favored for its crisp leads and pads.
* Access Virus (1997â€“present) â€“ A favorite in electronic and trance music for its powerful, lush sound.
* Moog Sub 37 (2014) â€“ A modern take on classic Moog designs, with deep modulation capabilities.
* Sequential Prophet-6 (2015) â€“ A modern reboot of the legendary Prophet-5 with updated features.
Software Synths (VSTs):
* Serum (Xfer Records) â€“ A go-to wavetable synth for modern electronic music.
* Massive (Native Instruments) â€“ Defined dubstep and bass music in the 2010s.
* Omnisphere (Spectrasonics) â€“ Known for its deep sound library and cinematic textures.


## Deepseek answer for most popular synths (also with categories)

The most popular synthesizers of all time are iconic for their sound, design, and influence on music. Hereâ€™s a list of some of the most legendary synths:

### **Analog Synths (Classic Era)**
1. **Moog Minimoog (1970)**  
   - The first portable synthesizer, defining the sound of analog synths.  
   - Used in prog rock, funk, and early electronic music.  
   - Famous users: Kraftwerk, Stevie Wonder, Pink Floyd.

2. **Roland TB-303 (1981)**  
   - Originally designed for basslines, it became the cornerstone of acid house and techno.  
   - Known for its squelchy, resonant sound.

3. **Roland TR-808 (1980)**  
   - A drum machine, but its iconic analog drum sounds (kick, snare, hi-hats) shaped hip-hop, electronic, and pop music.  
   - Famous in tracks by Marvin Gaye, Afrika Bambaataa, and modern producers.

4. **ARP 2600 (1971)**  
   - A semi-modular synth used in film scores (e.g., *Star Wars*) and by artists like Jean-Michel Jarre and Edgar Winter.

5. **Yamaha CS-80 (1976)**  
   - Known for its lush, expressive pads and leads.  
   - Used by Vangelis (*Blade Runner* soundtrack) and Stevie Wonder.

6. **Sequential Circuits Prophet-5 (1978)**  
   - The first fully programmable polyphonic synth.  
   - Used by Michael Jackson, Madonna, and Tangerine Dream.

---

### **Digital Synths (1980s and Beyond)**
1. **Yamaha DX7 (1983)**  
   - The best-selling synth of all time, thanks to its FM synthesis.  
   - Iconic for its electric piano, bass, and bell sounds.  
   - Used in 80s pop, rock, and R&B.

2. **Roland D-50 (1987)**  
   - A staple of late 80s and 90s music, known for its lush pads and digital textures.  
   - Used by Enya, Jean-Michel Jarre, and film composers.

3. **Korg M1 (1988)**  
   - The best-selling workstation synth, featuring iconic presets like the "Universe" pad and "Organ 2" (used in *Gonna Make You Sweat* by C+C Music Factory).

4. **Roland Juno-106 (1984)**  
   - A polyphonic analog synth with a warm, chorus-heavy sound.  
   - Popular in synth-pop, house, and indie music.

---

### **Modern Synths (2000s and Beyond)**
1. **Moog Subsequent 37 (2015)**  
   - A modern take on the Minimoog, loved for its versatility and rich analog sound.

2. **Korg Minilogue (2016)**  
   - An affordable analog polyphonic synth, popular with beginners and pros alike.

3. **Dave Smith Instruments Prophet-6 (2015)**  
   - A modern reimagining of the Prophet-5, combining vintage and modern features.

4. **Roland JD-XA (2015)**  
   - A hybrid synth combining analog and digital synthesis.

5. **Arturia MicroFreak (2019)**  
   - A unique digital/analog hybrid synth with a cult following for its experimental capabilities.

---

### **Modular Synths**
1. **Eurorack Modular System**  
   - A modular synth format that has become a standard for experimental and custom setups.  
   - Popularized by artists like Aphex Twin and Deadmau5.

2. **Moog Modular Systems (1960s-1970s)**  
   - The original modular synths used by Wendy Carlos (*Switched-On Bach*) and Keith Emerson.

---

### **Honorable Mentions**
- **Oberheim OB-Xa** (used by Van Halen, Prince)  
- **Korg MS-20** (a gritty semi-modular synth)  
- **Waldorf Wave** (a rare and powerful digital synth)  
- **Nord Lead** (a staple of live performances)  

---

These synths have shaped the sound of music across genres, from rock and pop to electronic and hip-hop. Their legacy continues to inspire musicians and producers today.

Regarding software synths:

Software synthesizers (soft synths) have become incredibly popular due to their affordability, flexibility, and ability to emulate classic hardware synths. Here are some of the most popular and influential soft synths of all time:

---

### **Classic Emulations**
1. **Arturia V Collection**  
   - A suite of software emulations of iconic synths like the Minimoog, Prophet-5, Jupiter-8, and DX7.  
   - Known for its accuracy and versatility.

2. **Native Instruments Monark**  
   - A faithful emulation of the Moog Minimoog, praised for its warm analog sound.

3. **Korg Legacy Collection**  
   - Includes software versions of the MS-20, Polysix, and Wavestation.

4. **Roland Cloud**  
   - Offers software versions of classic Roland synths like the Jupiter-8, Juno-106, and TB-303.

---

### **Modern Soft Synths**
1. **Serum by Xfer Records**  
   - A wavetable synth that has become a staple in EDM, dubstep, and modern production.  
   - Known for its intuitive interface and powerful sound design capabilities.

2. **Massive by Native Instruments**  
   - A wavetable synth that defined the sound of modern bass music and EDM.  
   - Used by Skrillex, Deadmau5, and many others.

3. **Omnisphere by Spectrasonics**  
   - A powerhouse synth with a vast library of sounds, combining synthesis and sample-based elements.  
   - Popular in film scoring, pop, and electronic music.

4. **Sylenth1 by LennarDigital**  
   - A virtual analog synth known for its warm sound and efficiency.  
   - Widely used in trance, house, and pop music.

5. **Spire by Reveal Sound**  
   - A versatile synth with a modern interface, popular in EDM and dance music.

6. **Pigments by Arturia**  
   - A visually stunning synth combining wavetable, virtual analog, and granular synthesis.  
   - Known for its flexibility and ease of use.

---

### **Experimental and Unique Synths**
1. **Absynth by Native Instruments**  
   - A semi-modular synth known for its atmospheric and evolving sounds.  
   - Popular in ambient and experimental music.

2. **Reaktor by Native Instruments**  
   - A modular environment for building custom synths and effects.  
   - Used by advanced sound designers and experimental artists.

3. **Granulator II (Max for Live)**  
   - A granular synthesis tool for Ableton Live, popular for creating textured, evolving sounds.

4. **Vital by Matt Tytel**  
   - A free wavetable synth with a Serum-like interface, gaining popularity for its power and accessibility.

---

### **Free and Budget-Friendly Synths**
1. **Surge XT**  
   - An open-source wavetable synth with a rich feature set.

2. **TyrellN6 by u-he**  
   - A free virtual analog synth with a classic sound.

3. **Dexed**  
   - A free FM synth based on the Yamaha DX7.

4. **TAL-NoiseMaker**  
   - A free virtual analog synth with a simple interface and great sound.

---

### **Hybrid and Sampler-Based Synths**
1. **Kontakt by Native Instruments**  
   - A sampler-based platform used for creating and playing realistic instruments and experimental sounds.

2. **Alchemy (in Logic Pro)**  
   - A powerful synth combining additive, spectral, granular, and sample-based synthesis.

3. **Falcon by UVI**  
   - A hybrid synth and sampler with deep sound design capabilities.

---

### **Honorable Mentions**
- **Diva by u-he** (analog modeling synth)  
- **Phase Plant by Kilohearts** (modular-style soft synth)  
- **Zebra by u-he** (hybrid synth for film scoring and sound design)  
- **ANA 2 by Sonic Academy** (versatile synth for modern genres)  

---

These soft synths have become essential tools for producers, offering everything from classic analog emulations to cutting-edge sound design capabilities. Many are used across genres, from pop and hip-hop to experimental and cinematic music.

## Best free synths to use

There are a lot of great free software synths available, whether youâ€™re looking for analog emulations, wavetable synthesis, or experimental sound design tools. Here are some of the best free synth plugins you can use:

### **Best Free Analog-Style Synths**  
1. **Vital (Matt Tytel)** â€“ Often called the â€œfree Serum,â€ this powerful wavetable synth has an intuitive interface and deep modulation options.  
2. **Surge XT** â€“ A versatile, open-source hybrid synth with subtractive, FM, and wavetable synthesis.  
3. **Tyrell N6 (u-he)** â€“ A classic analog-modeled synth inspired by the Roland Juno series.  
4. **OB-Xd (DiscoDSP)** â€“ A fantastic emulation of the classic Oberheim OB-X synth, great for lush pads and leads.  

### **Best Free FM Synths**  
5. **Dexed (Digital Suburban)** â€“ A faithful recreation of the Yamaha DX7, perfect for classic FM sounds.  
6. **TAL-Noisemaker (Togu Audio Line)** â€“ A simple but powerful synth with built-in effects and flexible modulation.  

### **Best Free Modular & Experimental Synths**  
7. **VCV Rack (Free Version)** â€“ A virtual modular synth environment similar to Eurorack hardware.  
8. **Helm (Matt Tytel)** â€“ A cross-platform synth with a fun, visual modulation system.  
9. **Zebralette (u-he)** â€“ A single-oscillator version of the powerful Zebra synth, great for learning wavetable synthesis.  

### **Best Free ROMplers & Sample-Based Synths**  
10. **LABS (Spitfire Audio)** â€“ A free collection of beautifully sampled instruments, great for cinematic sounds.  
11. **Piano One (Sound Magic)** â€“ A high-quality sampled grand piano.  

### **Best Free Synthwave & Lo-Fi Synths**  
12. **TAL-U-No-62 (Togu Audio Line)** â€“ A Juno-60 emulation with lush chorus effects.  
13. **PG-8X** â€“ An emulation of the Roland JX-8P, perfect for 80s synthwave vibes.  

There are many high-quality free software synths available that rival paid options in terms of sound and functionality. Hereâ€™s a list of some of the best free soft synths you can use:

---

### **Analog Emulations**
1. **Vital**  
   - A powerful wavetable synth with a Serum-like interface.  
   - Features include wavetable editing, FM synthesis, and a flexible modulation system.  
   - Free version available with a wide range of features.

2. **Surge XT**  
   - An open-source wavetable synth with a rich feature set.  
   - Includes three oscillators, multiple filter types, and extensive modulation options.

3. **TyrellN6 by u-he**  
   - A virtual analog synth with a classic sound.  
   - Great for bass, leads, and pads.

4. **TAL-NoiseMaker**  
   - A simple yet powerful virtual analog synth.  
   - Known for its warm sound and intuitive interface.

---

### **FM Synthesis**
1. **Dexed**  
   - A free FM synth based on the Yamaha DX7.  
   - Comes with thousands of presets and allows you to load DX7 sysex files.

2. **VOPM**  
   - Another FM synth emulating the Yamaha YM2612 chip (used in the Sega Genesis).  
   - Great for retro video game sounds.

---

### **Modular and Experimental**
1. **VCV Rack**  
   - A free modular synth environment with a vast library of modules.  
   - Perfect for creating experimental and complex sounds.

2. **Crystal by Green Oak**  
   - A hybrid synth combining subtractive, FM, and granular synthesis.  
   - Great for atmospheric and evolving textures.

3. **Pendulate (Max for Live)**  
   - A free granular synth for Ableton Live users.  
   - Ideal for creating unique, textured sounds.

---

### **Sampler-Based**
1. **Grace by One Small Clue**  
   - A simple and lightweight sampler with synthesis capabilities.  
   - Great for creative sound design.

2. **Sforzando**  
   - A free sampler that plays SFZ files.  
   - Comes with a library of high-quality sampled instruments.

---

### **Other Notable Free Synths**
1. **OB-Xd**  
   - A free emulation of the Oberheim OB-X synthesizer.  
   - Known for its warm, vintage sound.

2. **Synth1**  
   - A legendary free synth based on the Nord Lead 2.  
   - Comes with thousands of user-created presets.

3. **Helm**  
   - A polyphonic synth with a clean interface and powerful features.  
   - Includes a built-in EQ and compressor.

4. **PG-8X**  
   - A free emulation of the Roland JX-8P.  
   - Great for lush pads and retro sounds.

5. **Dragonfly Reverb + Triple Cheese**  
   - While primarily a reverb plugin, Triple Cheese is a quirky granular synth included in the bundle.  
   - Perfect for experimental sound design.

---

### **Free Synth Plugins for Specific DAWs**
1. **Ableton Live (Suite)**  
   - **Operator**: A built-in FM synth.  
   - **Wavetable**: A wavetable synth included in Live 10 and later.  
   - **Analog**: A virtual analog synth.

2. **Logic Pro**  
   - **Alchemy**: A powerful hybrid synth included in Logic Pro.  
   - **Retro Synth**: A versatile synth with analog, FM, wavetable, and sync modes.

3. **FL Studio**  
   - **Sytrus**: A powerful FM synth included in FL Studio.  
   - **Flex**: A free synth with a large library of presets.

---

### **Where to Find Free Synths**
- **Plugin Boutique**: Offers free synths and plugins regularly.  
- **Bedroom Producers Blog**: A great resource for finding free plugins.  
- **KVRAudio**: A database of free and paid plugins.

---

These free soft synths are perfect for beginners and professionals alike, offering a wide range of sounds and capabilities without breaking the bank. Whether youâ€™re into analog emulations, FM synthesis, or experimental sound design, thereâ€™s something here for everyone!

### Google Gemini response

It's fantastic that there are so many high-quality free software synthesizers available! Here's a breakdown of some of the best, categorized to help you find what you're looking for:

Top Recommendations:

Vital:
This is a powerful wavetable synth that rivals paid options. Its sound quality and feature set are exceptional. It's considered by many to be one of the very best free synths available. Â  
Surge XT:
An open-source, versatile synth with a robust wavetable engine. It offers a wide range of sonic possibilities and is constantly being updated. Â  
TyrellN6 (u-he):
Inspired by classic Roland synths, this is a fantastic virtual analog synth with a warm and rich sound. Â  
OB-Xd:
An excellent free emulation of the Oberheim OB-Xa, known for its lush and powerful sound.
PG8X:
A great software emulation of the Roland JX-8P.
Zebralette (u-he):
A single oscillator synth that is a smaller version of u-he's Zebra 3. High quality sound.
Other Notable Free Synths:

TAL Noisemaker:
A free synth inspired by the Roland Juno series.
Odin 2 (TheWaveWarden):
A powerful semi-modular synth with a wide range of features. Â  
Cherry Audio Voltage Modular Nucleus:
A free version of a modular synthesizer platform.
Full Bucket Music Synths:
This developer offers a collection of high-quality free synths that emulate classic Korg instruments. Â  
Key Considerations:

Type of Synthesis:
Consider what kind of sounds you want to create. Wavetable synths (like Vital and Surge XT) are great for modern sounds, while virtual analog synths (like TyrellN6 and OB-Xd) excel at classic analog tones.
Ease of Use:
Some synths have steeper learning curves than others. If you're a beginner, you might want to start with a simpler synth.
System Requirements:
Make sure the synth is compatible with your operating system and that your computer meets the minimum system requirements.
I hope this information helps you find the perfect free software synths for your music production needs!


## Lesson 08 - AM and FM

Wavetables is a type of oscillator. 
You get samples of maximum 1 second (more than one second is called sample based synthesis). And you repeat them.

* A usual problem is aliasing. If you record low frequency sample, this will have many overtones. When you transpose it to higher octaves (pitch), the overtones go above the 20KHz hearing range (and that means above nyquist limit, the notes get mirrored and we get "aliasing").


Envlope and sound problem discussion (that I did not understand).

We are making tremolo and vibrato, but using AM (amplitude modulation) and FM (frequency modulation).

### the gist

Modulation synthesis uses one signal (the modulator) to modulate the amplitude, frequency, or phase of another (the carrier) to create more complex signals

* FM specifically had crazy impact in music.

### AM 

It adds sidebands (you can visually see that it changes the frequencies).

AM creates two (left and right). If they lineup.

If one sideband goes to 0 frequency, it shifts upwards the wave (because of 0 Hz component, also called "DC component"). We usually use DC filter to remove just 0 Hz.

If freqM > freqC, the harmonics get mirrored and the phase gets inverted (goes do negative).

Carier is black signal, M is the modulation signal.

The heights are controlled by depth and offeset. 

if we add 3 components for our modulator, 

> Radio refers to the same processes. In AM, the M is the actual voices of the radio commentator, and each radio station is using a different carrier (they don't overlap).


They use dynamic eq to have a loud signal. It makes people think they have the clearest radio signal. 


```cpp
#include <klang.h>
using namespace klang::optimised;

struct MyAMSynth : Synth {
	struct AMNote : public Note {
		Sine carrier;
		Sine modulator;

		event on(Pitch pitch, Amplitude velocity) {
			param f = pitch -> Frequency;
			carrier.set(f, 0);
		}

		void process() {
			param rate = controls[0]; 
			// make it a proportion to get same timbre across the keyboard
			// if it's whole number, it's harmonic
			// 
			param depth = controls[1];
			param offset = controls[2];

			signal mod = depth * modulator(rate) + offset ;
			// setting the modulator frequency through the control
			// than change gain and offset and assign to mod
			carrier * mod >> out; // apply mod on the amplitude (multiplication)
		}
	};

	MyAMSynth () {
		controls = { Dial("Rate", 0, 800, 6),
		             Dial("Depth"), 
		             Dial("Offset") };
		notes.add<AMNote>(32);
	}
};

// check the spectrum (choose good resolution of FFT by right clicking)
```

* John Chowning: the guy that invented FM. He was an engineer and musician. He also wrote a book, which is really complicated for musicains. DX-7 synth was really popular and used FM.
* Yamaha and Stanford, where this guy worked, patented that and made loads of money.
* Guglielmo Marconi: invented the radio 


* bells cannot be harmonic because of their shape.
* Bristol for UK and Stanford for US are famous places music innovation hubs.


### FM

He adapted the FM radio to synthesis.

The modulation happens around the frequency of the note.
Now we don't get two sidebands but possibly infinite. 

Same as before, we get a modulator (oscillator/signal), use depth and offset.
But this time we manipulate the frequency/pitch of the note.

* with modest components we could now make many harmonics and sounds. we can make it cheaper, smaller and save presets. Yamaha made DX7 and it created 32 very different sounds (built in presets/patches).

* They had hardware sequencers to play really fast.

* Quincy Jones used it a lot.

Dexed FM modulation, better than DX7. you can download presets.
There is an emulator written in Klang.

> So many songs and sounds (Top Gun).

```cpp

#include <klang.h>
using namespace klang::optimised;

struct MyFMSynth : Synth {

	struct FMNote : public Note {
		Sine carrier;
		Sine modulator;
		ADSR adsr;
		param fc;

		event on(Pitch pitch, Amplitude velocity) {
			fc = pitch -> Frequency;
			carrier.reset();
			modulator.reset();
			adsr(0.001, 0, 1, 0.25);
		}

		event off(Amplitude velocity) {
			adsr.release();
		}

		void process() {
			param rate = controls[0] * fc; // set the fd (frequency of modulator) in relation to fc (frequency of the carrier)
			param depth = controls[1] * rate; // set depth in relation to fd 
			signal mod = modulator(rate) * depth + fc; // mod signal
			carrier(mod) * adsr >> out;
			if (adsr.finished())
				stop();
		}
	};

	MyFMSynth() {
		controls = {
			Dial("Rate", 0.01, 10, 6),
			Dial("Depth", 0, 10, 0.5)
		}; 
		notes.add<FMNote>(32);
	}
};

// beautiful to see in sonogram and spectrum
```

Now we are using the first ADSR to manipulate the carrier.

```cpp
#include <klang.h>
using namespace klang::optimised;

struct MyFMSynth : Synth {

	struct FMNote : public Note {
		Sine carrier;
		Sine modulator;
		ADSR adsr;
		param fc;

		event on(Pitch pitch, Amplitude velocity) {
			fc = pitch -> Frequency;
			carrier.reset();
			modulator.reset();
			param adsr_attack = controls[2];
			adsr(adsr_attack, 0, 1, 0.25);
		}

		event off(Amplitude velocity) {
			adsr.release();
		}

		void process() {
			param rate = controls[0] * fc; // set the fd (frequency of modulator) in relation to fc (frequency of the carrier)
			param depth = controls[1] * rate; // set depth in relation to fd 
			signal mod = modulator(rate) * depth + fc; // mod signal
			carrier(mod) * adsr >> out;
			if (adsr.finished())
				stop();
		}
	};

	MyFMSynth() {
		controls = {
			Dial("Rate", 0.01, 10, 6),
			Dial("Depth", 0, 10, 0.5),
			Dial("Attack", 0, 1, 0.01)
		}; 
		notes.add<FMNote>(32);
	}
};
```

And now we add an envelope to affect the depth of the modulation.
Can create a good base sound.

```cpp
#include <klang.h>
using namespace klang::optimised;

struct MyFMSynth : Synth {

	struct FMNote : public Note {
		Sine carrier;
		Sine modulator;
		ADSR adsr;
		param fc;
		Envelope env;

		event on(Pitch pitch, Amplitude velocity) {
			fc = pitch -> Frequency;
			carrier.reset();
			modulator.reset();
			param adsr_attack = controls[2];
			adsr(adsr_attack, 0, 1, 0.25);
			env = { { 0, 1}, { 0.5, 0 } }; // fall 1 to 0 in 0.5 secs
		}

		event off(Amplitude velocity) {
			adsr.release();
		}

		void process() {
			param rate = controls[0] * fc; 
			param depth = controls[1] * rate * env; // use env for depth
			signal mod = modulator(rate) * depth + fc; 
			carrier(mod) * adsr >> out;
			if (adsr.finished())
				stop();
		}
	};

	MyFMSynth() {
		controls = {
			Dial("Rate", 0.01, 10, 6),
			Dial("Depth", 0, 10, 0.5),
			Dial("Attack", 0, 1, 0.01)
		}; 
		notes.add<FMNote>(32);
	}
};

```

An operator = an oscillator followed by an envelope (and we have some knobs/controls outside).
FM synthesis is connecting two operators serially (one input of the other, creates interesting).

You can connect them in many ways, you can actually calculate some stuff.

The operator has two main parameters
* ratio: the signal that goes in
* depth: 
* it also has the envelopes parameters

FM8 is a Native Instruments similar synth.

* TX81z lately bass
* Manipulated Living (Donnie Darko, FM synthesis)

> TODO: create sequences of basses, match them. Also systemitise chords (dokareni).


> The envelopes in DX7, the enveloper were not ADSR.

The DX-7 free emulator is called Dexed (free plugin).

The patches are saved in `.syx` files. Sysex is just a way of transmitting synth specific data (usually patches, but sometimes firmware updates) over MIDI.

TODO: check Enya (boadicea), book of days, 

* [DX-7](https://yamahablackboxes.com/collection/yamaha-dx7-synthesizer/patches/)
some other 
* [Patches from drive](https://www.reddit.com/r/synthesizers/comments/e4jkt7/my_curated_dexeddx7_patches_3_banks/)

* [Awesome masterclass in sound design](https://youtu.be/jWorjBDcty4)
* [Awesome masterclass in music theory](https://youtu.be/_VvKeiwddPI)

* [Eurorack]()
	* amplitude modulation (ring modulation is the same, the original disappears and change the higher frequencies)
	* frequency


* style transfer is a common AI techniques
* wavetable


* good youtubers are doctor mix and matt johnson jamiroquai. eurorack.
* Mutable Instruments was a company with great euroracks that open sourced their models (emilie). here is the [archive](https://pichenettes.github.io/mutable-instruments-documentation/). They were making chips with software inside and knobs. They were flexible to communicate with each other and make sounds. Essentially a plugin can be a whole instrument. [github pages](https://pichenettes.github.io/mutable-instruments-documentation/modules/grids/open_source/).




## Lesson 07 - Subtractive synthesis

Adding a 3rd dimension. 

* We have seen plots: (amplitude and time), (frequency and amplitude), 

Short attack, exponential decay, no sustain.

Struck vs pluck.
The amplitude envelope is the shape of the sample.

Violin has attack, sustain (vibrato like) and release.

> vibrato: waver the pitch (rock the left hand with a violin)
> tremolo: waver the amplitude (move the right hand with a violin)

In synthesis, a popular envelope is ADSR. It provides three time controls (how long Attack, Decay, Release last?) and one level control (how loud sustain is?).

> The envelope can be used to control anything. You can control amplitude. But also the cutoff of a filter (we will do this later), and any other parameter.

if sustain = 0, we get a percusive sound.

The envolope is a signal generator (and we use it to control gain on the frequency oscilator).

```cpp
#include <klang.h>
using namespace klang::optimised;

struct ADSRSynth : Synth {

	struct ADSRSynthNote : public Note {
		Sine osc;
		ADSR adsr;

		event on(Pitch pitch, Amplitude velocity) {
			const param f = pitch -> Frequency;
			osc(f, 0);
			adsr(controls[0], controls[1], controls[2], controls[3]);
		}

		event off(Amplitude velocity) {
			adsr.release();
		}

		void process() {
			osc* adsr++ >> out;
			if (adsr.finished())
				stop();
		}
	};

	// Initialise plugin (called once at startup)
	ADSRSynth() {
		controls = {
			Dial("A"), Dial("D"), Dial("S"), Dial("R")	
		};

		notes.add<ADSRSynthNote>(32);
	}
};

```

There are 

Popular ADSR setpus:
* "The Swan" by Saint-Saen
* "Popcorn" (arpegiated) (better with Sawwave)
* "Jesu Joy of Man's Desiring" by Bach

Clara

Hotbutter popcorn.

Poeple who made synthesis popular in 60s,70s: 
* Isao Tomita, 
* Wendy carlos (bach music on new synthesizers)
* Vangelis (VLE, bladerunner 2049 was even better)
* until 60s, all sounds were acoustic
* jean michel jarre (no lyrics, he gave concerts in Russia and China during cold war) (7.5 M people in Moscow)

* synthpop in the 80s (Tangarine Dream e.g. Risky Business Tom Cruise film, Depeche Mode)
* stevie wonder was traditional musician (all jazz greats have some )
* BBOP by miles davies, Chamileon by Herbie Hancock


We can create any kind of envelope. We define the points of our graph.

```cpp
	struct MySynthNote : public Note {
		Sine osc;
		Envelope adsr;

		event on(Pitch pitch, Amplitude velocity) {
			osc(pitch -> Frequency, 0);
			adsr = { 
				{ 0.0,  0.0 },  
				// attack for 0.25s, to up to 1 (max amlitude)
				{ 0.25, 1.0 },
				// decay for 0.25s more, go to 0.5 of max amplitude
				{ 0.5,  0.5 } 
			};
			adsr.setLoop(2, 2);
		}

		event off(Amplitude velocity) {
			adsr.release(0.5);
		}

		void process() {
			osc * adsr >> out;
			if(adsr.finished())
				stop();
		}
	};
```

The sonogram shows time and frequency togehter (and amplituede is created with shadows).


Aphex Twin (british composer) has made a sonogram of his fame and released the song.

In the frequency spectrum, I was watching a bell.
But there is no bell actually. It's the spectrum plotting that lack precision, it's just "artifcats" from FFT.
You can either have good time resolution or good frequency resolution.


Let's make additive synthesis more powerful and add an ADSR envelope in each oscilator.
We are gonna make a guitar (plucky) sound.
In a guitar, the higher frequencies are attenudated (dampened) faster. ("dampen" means making wet/soggy)

```cpp
#include <klang.h>
using namespace klang::optimised;

#define N 8 // number of harmonics
// #define N 32 // number of harmonics

struct MyHarmonicOscillator : Oscillator {
	Sine osc[N];
	Envelope env[N];
	
	void set(param f){ // runs one time when we press the note
		for (int i = 0; i < N; i++){
			osc[i].set(f * (i+1));
			env[i] = {	// just setting decay
				{ 0, 1.f / N }, // start at full strength (divide by number of harmonics)
				{ 1.f / (i+1), 0 } // end at 0, the higher frequencies dampened (exponentially) faster
				// { 1.f - i * 1.f / N, 0 } // end at 0, the higher frequencies dampened (linearly) faster
			};
		}
	}

	void process(){
		signal mix = 0;
		for (int i = 0; i < N; i++){
			if (osc[i].frequency < fs.nyquist){
				mix += osc[i] * env[i];  // attenuate using the envelope!!
			}
		}
		mix >> out;
	}
};

//struct MyFirstSynth : Synth {
//
//	struct SimpleNote : public Note {
//		MyHarmonicOscillator osc;
//		param gain;
//
//		// velocity is how fast we hit the note (it's the dotted arrows in the diagram)
//		event on(Pitch pitch, Amplitude velocity) {
//			param frequency = pitch -> Frequency;
//  	   		osc.set(frequency);
//			gain = velocity * velocity * velocity;
//			debug.print("%f at %f\n", pitch.value, velocity.value);
//		}
//
//		void process() {
//			osc*gain >> out;
//		}
//	};
//
//	MyFirstSynth() {
//		notes.add<SimpleNote>(32);
//	}
//};




struct MySynth2 : Synth {

	struct MySynth2Note : public Note {
		MyHarmonicOscillator osc;
		ADSR adsr;

		event on(Pitch pitch, Amplitude velocity) {
			const param f = pitch -> Frequency;
			osc(f, 0);
			adsr(0.001, 0, 1, 0.25);
		}

		event off(Amplitude velocity) {
			adsr.release();
		}

		void process() {
			osc* adsr++ >> out;
			if (adsr.finished())
				stop();
		}
	};

	// Initialise plugin (called once at startup)
	MySynth2() {
		controls = {
			// UI controls and parameters
		};

		notes.add<MySynth2Note>(32);
	}
};
```

> If a surface reflects light, it reflects sound as well. If we want to dampen the sound, we use rough sufaces, cover corners, etc. 

The trigger is binary, when we use the key.
The velocity is how fast we hit the key.


Subtractive synthesis. 
Rather than using a complex sound, we use recording. Sample subtractive synthesis

> Now the most important thing is the filtering. We can have one oscilator (not sine, because it's not interesting) and filter harmonics to create interesting sounds.

TODO: what if we make a new wave (not sine, triangle, saw and square)?

* Moog (grandmother), Buhler are popular analogue synths (if a company has a name in synthesis is because you have a good filter)
* Semimodular (some modes are already hard connected for you)
* We can add more oscillators

ASK: 10 analogue synths you have to know about!!
ASK: what makes a good filter? what are the parameters?

Previously we used envelopes to dampen the higher harmonics faster. 
Now we are doing it with filtering.

```cpp


```

An LFO is an infinete periodic table.

The incredible thing about semi-modular analogue synths is they cost 2000/3000 GBP and they all do almost the same thing.
* The sounds with semi-modular has been  

Modular synthesis is a form of subtractive synthesis. 
* semi-modular have some preconnections
* Moog (terrible businessman)
* german company (Behringer): ripping of the designs (model 15 is suspiciously similar to mother-32)


TODO: non-linearly going down the frequency spectrum (as we perceive this)
TODO: familiarise with log vs linear (mapping things, etc)
TODO: familiarise with sounds (reverb, filters, lfos, sine/square/saw, ...)
TODO: investigate more synths that it has (detune saws, create super cool animations, check the supersaw that is heavily used in trance music) (check the[:w
])


mixing two saw waves are not really interesting.


We can do the project now.

```cpp
```

* synth: TB303, "Everybody Needs a 303" (sequencer) (TD-3-AM) 
* they were trying to recreate the bass sound, horribly failed
* they fucked up the filter design and later on lead to the creation of ACID house

## Lesson 06 - Additive synthesis

Enjoy and find a synthesis technique. 
You can use any of the effects we discussed. 
"What kind of instrument do I have in mind?", envelopes etc

> End project: develop your own synthesiser plugin with built-in effects processing.
	
* you are not used to listening instruments in empty space, there is always some reverb in what we hear as humans
* reverb is important in every synthesizer


Synthesis is the creation of sound, the generation of a signal.
Synthesis means "to create".
We hit a key on a keyboard, which is tied to a pitch.

The effects were always processing. 
Synthesizers, the are in time. We will get.
Velocity : (that is hit at) how hard/fast a key is pressed.
* MIDI is a keyboard centric system. Velocity doesn't make sense in all instruments.
* Harder velocity (value between 0.0 and 1.0)
* The note on effect

A violin can play anything (infinite pitches). Piano is more discrete.

* you can do hammer sound of piano (when you press/note on and release/note off)

* next time: release stage, generate some audio after

* we will be making polyphonic synthesizers
* we can have up to 32 notes (add them up)
* then we can add effects on top of that

* `on` function is called when pressing a note
* `Pitch` is an integer (between 0 to and 127, middle C is 60)

* it gives an ADSR envelope
* 

```cpp
#include <klang.h>
using namespace klang::optimised;

struct Simple : Synth {

	struct SimpleNote : public Note {
		Sine osc; // also Saw, ...

		event on(Pitch pitch, Amplitude velocity) {
			param frequency = pitch -> Frequency;
			osc.set(frequency, 0);
		}

		void process() {
			osc >> out;
		}
	};

	Simple() {
		notes.add<SimpleNote>(32);
	}
};
```

The velocity value we don't use in the previous snippet. We can store it.

```cpp
#include <klang.h>
using namespace klang::optimised;

struct MyFirstSynth : Synth {

	struct SimpleNote : public Note {
		Sine osc; // also Saw, ...
		param gain; // to store velocity, will be used as gain

		event on(Pitch pitch, Amplitude velocity) {
			param frequency = pitch -> Frequency; // this creates a mapping (from pitch to frequency) (you could even define just intoned mapping, or something else)
			osc.set(frequency, 0);
			// gain = velocity;	// we can do better
			gain = velocity * velocity * velocity; // our hearing is logarithmic, cubing is a good approximation
			debug.print("%f at %f\n", pitch.value, velocity.value);
		}

		void process() {
			osc*gain >> out;
		}
	};

	MyFirstSynth() {
		notes.add<SimpleNote>(32);
	}
};
```

Our perception is logarithmic.
If you half the amplitude, it wouldn't be havling the 
6 decibels is equivelant to doubling the sound.


Bach came up with the mathematical tuning we use today (in western music). He was a musical and mathematical genious.

* A4 = 880 
* A4 = 440Hz (called "concert pitch")
* A3 = 220Hz

"Concert pitch": it's the note to set, then tune the rest based on that. In orchestras, all of them test tuning in "concert pitch".

violin, viola, ...

Back in Bachs day, it was actually 432 Hz (which means we hear Bachs songs a bit sharper than they used to be).

An octrave is power of two.
`f * 2^n` to go up n octaves.

In western music, we split the octave in 12, therefore put `n = 1/12`:
`f* 2^(1/12) ~ f* 1.059` to move a semitone up. 

The "music of the spheres", divine.
Pythagorian tuning is just intoned.

5ths, 4ths and 3rds are close to "just intonations"
Somebody with perfect pitch could probably notice these slight differences.

Equal temperament is perfect for music that modulates in key.


It doesn't make sense to plot linearly, so we plot logarithmically.

The same story is with decibels and levels.


The viola, violin, trumpet can play the same note (base frequency). But they sound different (the overtones / harmonics are different for them). We say the have different **timbre** ("tam-brah").

The sinewave is the only sound that has only one frequency.


Even if you remove the fundamental, your brain will understand that it's missing.
Our brains are pattern recognition machines.

A violin string (producing sound from friction) has more noise/harmonics than a guitar string (which is just picking a string).

Bells are not really harmonic because they are designed to be resonant (which makes them loud).

No consonance or disconance will lead to noise.


Additive synthesis is a simple but powerful way to create sounds. You essentially use sinewaves to create the fundamentals of the notes.

[YT - How Additive Synthesis Works](https://youtu.be/wGkdb6YlLgg)

> additive synthesis has been around for ages. AI can make it work. eventually, everything will be additive synthesis according to this guy.
> essentially, if you change pitch, usually the pattern stays the same (he uses adobe audition program).

* the FFT takes the sound and finds the frequencies

<!-- -6db comes from equalty  -->

Let's make a sawwave with additive synthesis.
We are going to create our own oscillator. Specifically, I'm going to create a saw oscilator by using the sine oscilators to reproduce the relevant harmonics that would exist in the saw harmonic spectrum.

```cpp
#include <klang.h>
using namespace klang::optimised;

#define N 8 // number of harmonics

struct MySawOscillator : Oscillator {
	Sine osc[N];
	
	void set(param f){ // runs one time when we press the note
		for (int i = 0; i < N; i++){
			osc[i].set(f * (i+1));
		}
	}

	void process(){
		signal mix = 0;
		for (int i = 0; i < N; i++){
			if (osc[i].frequency < fs.nyquist){ // the sample rate limits the maximum frequency we can produce
				mix += osc[i] /(i+1);  // attenuate the amplitudes of the frequencies
			}
		}
		mix >> out;
	}
};

struct MySquareOscillator : Oscillator {
	Sine osc[N];
	
	void set(param f){ // runs one time when we press the note
		for (int i = 0; i < N; i++){
			osc[i].set(f * (2*i+1));
		}
	}

	void process(){
		signal mix = 0;
		for (int i = 0; i < N; i++){
			if (osc[i].frequency < fs.nyquist){ // the sample rate limits the maximum frequency we can produce
				mix += osc[i] /(2*i+1);  // attenuate the amplitudes of the frequencies
			}
		}
		mix >> out;
	}
};

struct MyFirstSynth : Synth {

	struct SimpleNote : public Note {
		MySawOscillator osc;
		// MySquareOscillator osc; 
		param gain; // to store velocity, will be used as gain

		event on(Pitch pitch, Amplitude velocity) {
			param frequency = pitch -> Frequency; // this creates a mapping (from pitch to frequency) (you could even define just intoned mapping, or something else)
  	   		osc.set(frequency);
			gain = velocity * velocity * velocity; // our hearing is logarithmic, cubing is a good approximation
			debug.print("%f at %f\n", pitch.value, velocity.value);
		}

		void process() {
			osc*gain >> out;
		}
	};

	MyFirstSynth() {
		notes.add<SimpleNote>(32);
	}
};
```

Aliasing happens when we produce frequencies above the Nyquist limit (it's relevant')
A collection of orchestral sounds, here: [Sounds from University of Iowa](https://theremin.music.uiowa.edu/index.html).

Pianos just their timbre from lower to higher notes (hammering on three strings in bottom notes vs hammering on two strings on the top notes).

### Resynthesis: Korg M1 Organ sample (at C2)

Resynthesis is creating again a sound digitally from scratch.
The Audacity is a popular open-source free software for audio analysis.

> This was one of the most stunning moments of the whole class personally. With only a few frequencies, selected in the correct frequencies, we can create a magnificent electronic sound that I would love to hear in a real electronic track (and is actually featured in many electronic tracks). With only 6 frequencies, you can make M1 Korg sound, and it's already pretty neat.

```cpp
#include <klang.h>
using namespace klang::optimised;

// Measurements from Korg M1 Organ sample (at C2):
// ====================================================
//    65Hz,   131Hz,   196Hz,   263Hz,   327Hz,   393Hz
// -14.5dB, -14.2dB, -14.3dB, -50.0dB, -47.2dB, -24.5dB

#define N 6 // number of harmonics
const float FREQ[N] = { 65/65.f, 131/65.f, 195/65.f, 263/65.f, 327/65.f, 393/65.f }; // (normalised to f0)
const dB GAIN[N] = 	{ -14.5+12, -14.2+12, -14.3+12, -50.0+12, -47.2+12, -24.5+12 }; // (in dB)	

struct MyKorgM1Organ : Oscillator {
	Sine osc[N];
	
	void set(param f){ // runs one time when we press the note
		for (int i = 0; i < N; i++){
			osc[i].set(f * FREQ[i]);
		}
	}

	void process(){
		signal mix = 0;
		for (int i = 0; i < N; i++){
			if (osc[i].frequency < fs.nyquist){ // the sample rate limits the maximum frequency we can produce
				mix += osc[i] * (GAIN[i] -> Amplitude);  // attenuate the amplitudes of the frequencies
			}
		}
		mix >> out;
	}
};

struct MyFirstSynth : Synth {
	struct SimpleNote : public Note {
		MyKorgM1Organ osc;
		param gain; // to store velocity, will be used as gain

		event on(Pitch pitch, Amplitude velocity) {
			param frequency = pitch -> Frequency; // this creates a mapping (from pitch to frequency) (you could even define just intoned mapping, or something else)
  	   		osc.set(frequency);
			gain = velocity * velocity * velocity; 
			debug.print("%f at %f\n", pitch.value, velocity.value);
		}

		void process() {
			osc*gain >> out;
		}
	};

	MyFirstSynth() {
		notes.add<SimpleNote>(32);
	}
};
```

I will be rewriting the above code using a vector of pairs of frequency and dB (no normalisation, first harmonic is the fundamental), in order to make the oscillator super modular.

```cpp
#include <vector>
#include <klang.h>
using namespace klang::optimised;

struct Harmonic {
	int freq; // frequency (Hz)
	dB gain; // amplitude/gain (dB) 
	Harmonic(int in_freq, dB in_gain)
	: freq(in_freq), gain(in_gain)	
	{}
};

struct MyModularOscillator : Oscillator {
	std::vector<Sine> osc;
	std::vector<Harmonic> hs; // harmonics
	
	MyModularOscillator(){
		// Measurements from Korg M1 Organ sample (at C2):
		// ====================================================
		//    65Hz,   131Hz,   196Hz,   263Hz,   327Hz,   393Hz
		// -14.5dB, -14.2dB, -14.3dB, -50.0dB, -47.2dB, -24.5dB
		hs = { 
			Harmonic{65, -14.5+12},
			Harmonic{131, -14.2+12}, 
			Harmonic{195, -14.3+12}, 
			Harmonic{263, -50.0+12}, 
			Harmonic{327, -47.2+12}, 
			Harmonic{393, -24.5+12}, 
		};
		osc = std::vector<Sine>(hs.size(), Sine());
	}

	void set(param f){ // runs one time when we press the note
		const float base_freq = hs[0].freq; // convert to float to create float division
		for (int i = 0; i < hs.size(); i++){
			osc[i].set(f * (hs[i].freq / base_freq)); // normalising
		}
	}

	void process(){
		signal mix = 0;
		for (int i = 0; i < hs.size(); i++){
			if (osc[i].frequency < fs.nyquist){ // the sample rate limits the maximum frequency we can produce
				mix += osc[i] * (hs[i].gain -> Amplitude);  // attenuate the amplitudes of the frequencies
			}
		}
		mix >> out;
	}
};

struct MyFirstSynth : Synth {
	struct SimpleNote : public Note {
		MyModularOscillator osc;
		param gain; // to store velocity, will be used as gain

		event on(Pitch pitch, Amplitude velocity) {
			param frequency = pitch -> Frequency;
  	   		osc.set(frequency);
			gain = velocity * velocity * velocity; 
		}

		void process() {
			osc*gain >> out;
		}
	};

	MyFirstSynth() {
		notes.add<SimpleNote>(32);
	}
};
```

### recreating any sound

A collection of orchestral sounds, here: [Sounds from University of Iowa](https://theremin.music.uiowa.edu/index.html). Specifically for the following, I am using this [brass trumpet sound (C4)](https://theremin.music.uiowa.edu/MISBbtrumpet.html).
Using the [Audacity]() software, i can crop the note I want and analyze it by ploting the spectogram.
Then, I can manually create a table of pairs (frequency and dB) of harmonics I want to use to reproduce the sound (I am using the peaks I visually see).

Using the same code as before, but having pairs:
```cpp
#include <utility>
#include <vector>
#include <klang.h>
using namespace klang::optimised;

using HMap = std::vector<std::pair<float, dB>>; // harmonic pairs (Hz / dB) (first pair is the fundamental)
struct MyModularOscillator : Oscillator {
	std::vector<Sine> osc;
	HMap hs; // harmonics
	int enhance_dBs; // enhance dBs
	
	static const HMap getDefaultHs(){
		static const HMap d_hs = { 
			{65, -14.5},
			{131, -14.2}, 
			{195, -14.3}, 
			{263, -50.0}, 
			{327, -47.2}, 
			{393, -24.5}, 
		};
		return d_hs;
	}

	MyModularOscillator(HMap in_hs = getDefaultHs()){
		hs = in_hs.size() > 0 ? in_hs : getDefaultHs(); // we need at least one harmonic
		osc = std::vector<Sine>(hs.size(), Sine());
	}


	void set(param f){ // runs one time when we press the note
		const float base_freq = hs[0].first;
		for (int i = 0; i < hs.size(); i++){
			const auto& [freq, gain] = hs[i];
			osc[i].set(f * (freq / base_freq)); // normalising
		}
	}

	void process(){
		signal mix = 0;
		for (int i = 0; i < hs.size(); i++){
			const auto& [freq, gain] = hs[i];
			if (freq < fs.nyquist){ // the sample rate limits the maximum frequency we can produce
				mix += osc[i] * (gain -> Amplitude);  // attenuate the amplitudes of the frequencies
			}
		}
		mix >> out;
	}
};

// -------- visually investigate frequency spectrum with Audacity --------
const HMap trumpet_hs = {
	{268, -41.5}, {528, -30.5}, {788, -28.4}, {1048, -24.1}, {1309, -21.4}, 
	{1570, -26.2}, {1829, -30.9}, {2090, -40.5}, {2349, -48.6}, {26.11, -53.1}
};

const HMap sopsax_hs = {
	{270, -23.6}, {532, -28.2}, {795, -26.5}, {1057, -38.6}, 
	{1320, -56.0}, {1590, -50.1}, {1860, -56.8}, {2121, -53.9}
};

const HMap flute_hs = {
	{325, -19.5}, {658, -31.3}, {982, -36.8},
	{1310, -47.8}, {1636, -47.2}, {1960, -42.7}
};

const HMap xylophone_hs = {
	{416, -23.4}, {586, -54.0}, {673, -58.5}, {1046, -45.7}, {1260, -14.4}, 
	{1582, -58.5}, {1763, -60.8}, {2565, -26.1}, {2736, -16.6}, {3454, -54.4}, 
	{4332, -48.6}, {4837, -45.3}, {5419, -42.1}, {6100, -39.5}, {6666, -52.3}, {7428, -55.4}
};

// -------- i also asked ChatGPT to produce some sounds --------
// Organ (Smooth, Hollow Sound)
// A pipe organ-like sound is created using strong odd and even harmonics with a smooth falloff.
const HMap gpt_organ_hs = {{1, 0},{2, -6},{3, -12},{4, -18},{5, -24},{6, -30}};

// Clarinet (Warm, Hollow, Woody)
// Clarinet timbre is mainly composed of odd harmonics.
const HMap gpt_clarinet_hs = {{1, 0},{3, -8},{5, -15},{7, -22},{9, -28}};

// Electric Guitar (Plucky, Bright, Metallic) 
// A bright, twangy sound with strong odd and even harmonics, slightly detuned higher harmonics
const HMap gpt_electric_guitar_hs = {{1, 0},{2, -5},{3, -9},{4, -12},{5, -15},{6, -18},{7, -20}};
// Trumpet (Brassy, Bright, Sharp)
// A brassy sound has strong odd harmonics with slow amplitude decay.
const HMap gpt_trumpet_hs = {{1,0.0},{2,-4.0},{3,-8.0},{4,-12.0},{5,-14.0},{6,-17.0},{7,-20.0}};
// Synth Pad (Soft, Airy, Dreamy)
// A soft pad sound with gentle harmonic content.
const HMap gpt_synth_hs = {{1,0.0}, {2,-10.0}, {3,-15.0}, {4,-20.0}, {5,-25.0}, {6,-30.0}, {7,-35.0}};


struct MyFirstSynth : Synth {
	struct SimpleNote : public Note {
		MyModularOscillator osc;
		param gain; // to store velocity, will be used as gain

		SimpleNote()
		// : osc()
		// : osc(trumpet_hs) // use name of preset here
		// : osc(flute_hs)
		: osc(gpt_synth_hs)
		{}

		event on(Pitch pitch, Amplitude velocity) {
			param frequency = pitch -> Frequency;
  	   		osc.set(frequency);
			gain = velocity * velocity * velocity; 
		}

		void process() {
			osc*gain >> out;
		}
	};

	MyFirstSynth() {
		notes.add<SimpleNote>(32);
	}
};
```


### more interesting links

* [sound synthesis in another language](https://flossmanual.csound.com/sound-synthesis/additive-synthesis)
* [types of synthesis](https://www.youtube.com/watch?v=gJkxGvhOS-M&ab_channel=matrixsynth)

### chat gpt explaining decibels

Our perception of loudness follows a **logarithmic** scale, meaning that a **halving of perceived loudness** corresponds to a specific reduction in sound intensity.

In decibels (dB), loudness is measured as:

\[
L = 10 \log_{10} \left(\frac{I}{I_0}\right)
\]

where \( I \) is the intensity of the sound.

A **halving of perceived loudness** corresponds to a decrease of about **-10 dB**. Since intensity is proportional to the **square** of the wave amplitude (\( I \propto A^2 \)), we can derive the required amplitude reduction:

\[
-10 = 20 \log_{10} \left(\frac{A_{\text{new}}}{A_{\text{old}}}\right)
\]

Solving for \( A_{\text{new}} \):

\[
\frac{A_{\text{new}}}{A_{\text{old}}} = 10^{\frac{-10}{20}} = 10^{-0.5} \approx 0.316
\]

Thus, to make a sound appear **half as loud**, you should **reduce the amplitude of the wave to approximately 31.6% of its original value**.


More about.

You're looking for a function that maps a **perceived loudness fraction** \( g \) (where \( g = 0.5 \) means half the perceived loudness) to a **gain factor** that should be applied to the amplitude of the wave.  

We already established that loudness perception follows a **logarithmic** scale, and the relationship between **perceived loudness** \( g \) and **amplitude** \( A \) is:

\[
A \propto g^{\log_{10}(0.5)/\log_{10}(10^{-0.5})}
\]

which simplifies to:

\[
A = g^{0.301}
\]

A good practical approximation of this function is:

\[
A = g^{1/3}
\]

### Why \( g^{1/3} \)?
- \( g^{1/3} \) is a **computationally simple approximation** of \( g^{0.301} \) and works well for practical use.
- It maintains the key property: when \( g = 0.5 \), it gives \( A \approx 0.316 \), matching the correct amplitude scaling.

### Example Values:
| Perceived Loudness \( g \) | Computed Amplitude Gain \( g^{1/3} \) |
|-----------------|-----------------------|
| 1.0 (100%)     | 1.0                   |
| 0.5 (50%)      | ~0.316                 |
| 0.25 (25%)     | ~0.177                 |
| 0.1 (10%)      | ~0.10                  |

So, you can use:

\[
A = g^{1/3}
\]

as a simple function to adjust amplitude based on desired perceived loudness.

## Lesson 05 - Modulation

## first half modulation

modulation effects: Flanger, Chorus
* combining things we have learned

* chorus of different types: multiple voices (ensemble effect) vs New Order sound 

We have already seen modulation with Whah-What and Tremolo.

modulation means controling/chaning one parameter with an LFO (low frequency oscillator, 1Hz - 10Hz). Meaning 

* A tremolo effect is created by modulating amplitude/level using an LFO for the gain parameter.
* A wah-wah effect is created by modulating filter cutoff using an LFO for the cutoff parameter.
* A flanger or chorus (mod delay) effects are created by modulating time (affects pitch and frequency) using an LFO for the delay time parameter.
	* LFO-modulated delay repeatedly speeds up and slows down the signal, in turn modulating frequency and pitch, producing a vibrato effect.


> we multiply and add with delay to keep the range to positive [0, 2*delay] (instead of [-delay, delay] range)

Let's make the Mod Delay effect.    musically this is related to vibrato.

* vibrato: the things violins or guitars do, changing the pitch slightly

```cpp
#include <klang.h>
using namespace klang::optimised;

// Mod Delay
struct ModDelay : Effect {
	Delay<192000> delay;
	Sine lfo;

	ModDelay() {
		controls = { 
			{ "Mod", Dial("Rate"), // the velocity/frequency of LFO (usually 1-10 Hz) (how fast it changes)
			         Dial("Depth") } // the amount of time we go back (usually some miliseconds)
		};
	}

	void process() {
		param rate = controls[0]*(10-1) + 1; // range: 1 to 10 Hz
		param depth = controls[1] * 0.001;  // range: 0 to 0.001 seconds (delay time in seconds)
		// using the feedforward delay
		in >> delay;
		signal mod = lfo(rate) * depth + depth;
		// output the modulated delay
		delay(mod * fs) >> out;
	}
};
```

what if depth is much bigger (sounds like scratching).
essentially the scracting sound (which can be made in DJ console) changes depth a lot.

```cpp
#include <klang.h>
using namespace klang::optimised;

// Mod Delay
struct ModDelay : Effect {
	Delay<192000> delay;
	Sine lfo;

	ModDelay() {
		controls = { 
			{ "Mod", Dial("Rate"), // 
			         Dial("Depth") }
		};
	}

	void process() {
		param rate = controls[0]*(10-1) + 1; // range: 1 to 10 Hz (frequency range of oscilation - aka how fast do we change the parrameter)
		param depth = controls[1];  // range: 0 to 1 seconds (delay time)
		// using the feedforward delay
		in >> delay;
		signal mod = lfo(rate) * depth + depth;
		// output the modulated delay
		delay(mod * fs) >> out;
	}
};
```

flanger: essentially mod delay plus original signal
* popular effect for guitars
* it creates curves in frequency domain

The "dry" singal is the original signal (before effect).
The "wet" signal is after you changed it (after effect).
Flanger was adding back the dry signal to mod delayed "wet" signal essentially.

```cpp
#include <klang.h>
using namespace klang::optimised;

// Mod Delay
struct FeedForwardFlanger : Effect {
	Delay<192000> delay;
	Sine lfo;

	FeedForwardFlanger() {
		controls = { 
			{ "Mod", Dial("Rate"), // 
			         Dial("Depth") }
		};
	}

	void process() {
		param rate = controls[0]*(10-1) + 1; // range: 1 to 10 Hz
		param depth = controls[1] * 0.001;  // range: 0 to 0.001 seconds (delay time in seconds)
		// using the feedforward delay
		in >> delay;
		signal mod = lfo(rate) * depth + depth;
		// output the modulated delay
		in + delay(mod * fs) >> out;
	}
};

```


what if we make use feedback delay (instead of feed forward?)

remember how to distinguish in block diagrams:
* feed forward: input signal goes to delay 
* feedback: output signal goes into delay (and we add it to output)

```cpp
#include <klang.h>
using namespace klang::optimised;

// Mod Delay
struct FeedbackFlanger : Effect {
	Delay<192000> delay;
	Sine lfo;

	FeedbackFlanger() {
		controls = { 
			{ "Mod", Dial("Rate"), 
			         Dial("Depth"), 
					 Dial("Feedback") }
		};
	}

	void process() {
		param rate = controls[0]*(10-1) + 1; // range: 1 to 10 Hz
		param depth = controls[1] * 0.001;  // range: 0 to 0.001 seconds (delay time in seconds)
		param feedback_gain = controls[2];

		signal mod = lfo(rate) * depth + depth;
		signal feedback = delay(mod * fs) * feedback_gain;
		in + feedback >> out;
		out >> delay;
	}
};

```

You can add noise to fill the frequency domain (and you can visulaise the changes)

For modulating effects:
* Triangle and Sine are usually th ebest 
* Square and Saw are not usually used, because it is like reseting itself (and we lose some delays)


* the New Order bass player always uses kind of flanger/chorus effect.

* feedback flanger is more Blonde effect.


> reverb and chorus are in all the dj decks

* chorus: it's like many people sing, like a choir

3 delays with different effects
* we want to seperate voices so longer delays


Chorus (essentially an ensemble of feedfoward flangers with differenet rates and depths):
```cpp
#include <klang.h>
using namespace klang::optimised;

struct MyChorus : Effect {
	Delay<192000> delay; // we can use only one delay because it's feed forward
	// otherwise we would use the output and that would affect each delay
	Sine lfo[3];
	param rates[3] = { 2.5, 3, 3.5 }; // Hz
	param depths[3] = { 0.00045, 0.00050, 0.00055 }; // secs

	MyChorus() {
		// set rates for LFOs
		for (int i = 0; i < 3; i++){
			lfo[i](rates[i]);
		}
	}

	void process() {
		in >> delay;
		signal sig = in;
		for (int i = 0; i < 3; i++){
			signal mod = lfo[i] * depths[i] + depths[i];
			sig += delay(mod * fs);
		}
		sig * 0.5 >> out; // attenuating a bit
	}
};
```

We can update with more LFOs and signals:
```cpp
#include <klang.h>
using namespace klang::optimised;

struct MyChorus : Effect {
	Delay<192000> delay;
	static const int max_amount = 5;
	Sine lfo[max_amount];
	param rates[max_amount] = { 2.5, 3, 3.5, 4.0, 4.5 }; // Hz (evenly spaced)
	param depths[max_amount] = { 0.00045, 0.00050, 0.00055, 0.00060, 0.00065 }; // secs (evenly spaced)

	MyChorus() {
		controls = { 
			Dial("Gain", 0.0, 1.0, 0.5), 
			Dial("Voices (INT)", 0.0, 5.0, 1.0)
		};
		// set rates for LFOs
		for (int i = 0; i < max_amount; i++){
			lfo[i](rates[i]);
		}
	}

	void process() {
		param gain = controls[0];
		int amount = int(controls[1]); // amount of voices (LFOs)
		in >> delay;
		signal sig = in;
		for (int i = 0; i < amount; i++){
			signal mod = lfo[i] * depths[i] + depths[i];
			sig += delay(mod * fs);
		}
		sig * (1.0/(amount+1)) * gain >> out;
	}
};
```

Enhancments:
* dial to multiply (control) rates and depth (use smooth)
* random numbers for rates
* changing rates more often

When the values for rates and depths are evenly spaced, the sound is "flanger"-like.
The more evenly spaced the rates and depths are, the more "flanger"-like effect.

You can modulate distorion and filters as well.

Different way (extension). Filtering and distortion be used as well.
* Before or after distorion?
* distortion adds harmonic content (adding filter on the start will make this content shine).
* adding a filter on the end (it's kind of EQ, if you add too many harmonics, you erase them).

U2 discoteque is kinda like "modulated distorion?".

### extras 

The manual by Edelweiss: a psynical way of how to make hit songs
* by Bill Drummond
* "bring me edelweiss" by Edelweiss (stealing SOS by abba, yodel by sound of music, ...)
* the also wrote "3 A.M. Eternal" (guns of Mu Mu)


* audio processes has many block diagrams
* The computer music tutorial by Curtis Road (goes academically, refernces)
* will pirkle books (specific things)

* [Berkley](https://youtu.be/c3udLCvoCC0) explaining simple concepts

TODO idea: Use AI to optimise parameters of many models. And then start producing plugins.

## Lesson 04 - Delay

In this lesson we are going to look at delay:
* We will look simple echo effects and then feedback.
* We will make a reverb as well (mono, stretch goal to make stereo).
* We will look at impulse responses.

> Delays buffer a signal in memory to recall later, giving access to previous samples...

* Essentially, we move a sound later in time.
* The buffer will hold all the necessary values of the past that we will need.
* The implementation happens using a ring buffer (essentially shifting the start of the list instead of all the elements).

* The z-1 block diagram is a one-sample delay.
* The time is usually a variable of the dealy system (how long ahead to reproduce the past sound).


Let's implement an Echo effect. In it's simplest form it is adding a quieter dealyed signal (attenuated).
The echo practially gives a good sense of space (like listening music into an open area). That is because in real life, we here many echoes of every sound, because it bounces on surfaces around the room.

```cpp
#include <klang.h>
using namespace klang::optimised;

struct MyEcho : Effect {
	Delay<192000> delay; // we assume maximum sample rate of 192kHz, so our memory should be at least that to hold 1 second of past data

	MyEcho() {
		controls = { 
			{ "Echo", Dial("Time", 0.0, 1.0, 0.5),	// in seconds
			          Dial("Gain", 0.0, 0.99) }
		};
		presets = { { "Low Time / Low Gain",    { 0.23, 0.15 } }, // loading interesting presets, can be selected from the UI
					{ "Mid Time / High Gain", { 0.55, 0.88 } },
		};
	}

	void process() {
		param time = controls[0];
		param gain = controls[1];

		// every time we add something to the delay, the head moves	
		in >> delay;  // send input to the delay
		in + gain * delay(time * fs) >> out; // echo is the delayed signal but quitter
	}
};
```

We now want feedback, that why save the output to the saved samples (in delay array/buffer).
This way, we save all of the previous echoes. 

```cpp
#include <klang.h>
using namespace klang::optimised;

struct MyEcho : Effect {
	Delay<192000> delay;

	MyEcho() {
		controls = { 
			{ "Echo", Dial("Time"),
			          Dial("Gain", 0.0, 0.99) }
		};
	}

	void process() {
		param time = controls[0];
		param gain = controls[1];
				
		in + gain * delay(time * fs) >> out; // echo is the delayed signal but quitter
		out >> delay; // feeed the output to the delay
	}
};
```

> note that the output signal is a summation of two signals. If the gain is high enough, the signal can exponentially start growing and crash our system/speakers etc. 

This is a good moment to pause and talk about resonance.
It's possible that with bad timing, the amplitudes line up, meaning that: 
* the positives will line up with positivies
* the negatives will line up with negatives
This could happen e.g if the time parameter is equal to 1 bar of our sample.
This lining up would make the sound to loud (resonance)

> Resonance just means "things vibrating together, aka in the same frequency". It can be good or bad, depneding on the scenario. 
* It's bad when it magnifies the amplitude to our signal (and resonant delay produces sounds that could be described as "ringy" and are unpleasant). 
* It's good when it makes the sound powerful (could be described as "sharp").

> â€œResonanceâ€ is also used in spoken English to suggest agreement. â€œHer ideas really resonate with how I feel.â€ 

**Huge mind connection**: if time is really low in the echo filter, it effectively becomes a filter, specifically and IIR (infinate impulse response) filter

Easter egg song: "this is the sound of C" by Confettis in 1980s.


In the ping pong, the left and right signals are delayed and **reversed** simulateanously. This creates a really interesting effect.

```cpp
#include <klang.h>
using namespace klang::optimised;

struct MyPingPong : Stereo::Effect {
	Stereo::Delay<192000> delay;

	MyPingPong() {
		controls = { 
			{ "Left",  Dial("Time"),
			           Dial("Gain", 0, 0.99) },
			{ "Right", Dial("Time"),
			           Dial("Gain", 0, 0.99) }
		};
	}
	
	// feedforward delay (we only read from an echoless sample)
	void process() {
		stereo::signal time = { controls[0], controls[2] };
		stereo::signal gain = { controls[1], controls[3] };
		
		in.l >> delay.l;
		in.l + delay.l(time.l * fs) * gain.l >> out.l;

		in.r >> delay.r;
		in.r + delay.r(time.r * fs) * gain.r >> out.r;
	}
```
```cpp
#include <klang.h>
using namespace klang::optimised;

struct MyPingPong2 : Stereo::Effect {
	Stereo::Delay<192000> delay;

	MyPingPong2() {
		controls = { 
			{ "Left",  Dial("Time"),
			           Dial("Gain", 0, 0.99) },
			{ "Right", Dial("Time"),
			           Dial("Gain", 0, 0.99) }
		};
	}
	
	// feedback delay (we read samples that contain previous echoes)
	void process() {
		stereo::signal time = { controls[0], controls[2] };
		stereo::signal gain = { controls[1], controls[3] };
		
		in.l >> delay.l;
		in.l + delay.l(time.l * fs) * gain.l >> out.l;

		in.r >> delay.r;
		in.r + delay.r(time.r * fs) * gain.r >> out.r;
	}
};
```

flatter echo (kind of ringy echo)
* in bathrooms with ringy, tinny echo, because the tile parallel wall have many echoes

Easter egg song: "Electric counterpoint" by Steve Reich

### impulse 

Impulse is a momentary burst of input (a sample of amplitude 1 for example). An impulse response is the output of a system over time in response to an impulse.

You can plot the impulse to understand the system.
Since the delay will never actually become zero (based on zeno's paradox) but is decreased gradually through the gain, we plot until `t60`. -60 dB is considered silence (for human hearing) and `t60` is the amount of time for an impulse response to reach -60 dB (silence).


* Midi is a music protocol. Every note (key in piano) is assigned an integer. Middle C is 60. It was created in 1983 and is widely popular today.


For the following effect, we make the delay pattern of multiple feedforward signals.

```cpp
#include <klang.h>
using namespace klang::optimised;

struct Patterns : Effect {
	Delay<192000> delay;

	Patterns() {
		controls = { 
			{ "Delay 1", Dial("Time"), Dial("Gain") },
			{ "Delay 2", Dial("Time"), Dial("Gain") },
			{ "Delay 3", Dial("Time"), Dial("Gain") },
		};
	}

	void process() {
		param time[] = { controls[0],controls[2],controls[4] };
		param gain[] = { controls[1],controls[3],controls[5] };
		
		in >> delay;
		signal taps = 0;
		for (int i = 0; i < 3; i++){ // using a for loop
			taps += gain[i] * delay(fs * time[i]);
		}
		in + taps >> out;
	}
};
```

Select "Plot Impulse Response" in klang to see plot.
We also add pass the echo through a filter (to gradually keep only the low frequencies of the echoes, which "makes the sound duller").

```cpp
#include <klang.h>
using namespace klang::optimised;

struct MyEchoWithFilter : Effect {
	Delay<192000> delay;
	LPF filter;

	MyEchoWithFilter() {
		controls = { 
			{ "Echo", Dial("Time"),
			          Dial("Gain", 0.0, 0.99) }
		};
	}

	// this runs less frequently (once per buffer) 
	void prepare(){
		filter.set(controls[2]);
	}

	void process() {
		param time = controls[0];
		param gain = controls[1];
				
		in + gain * delay(time * fs) >> out; // echo is the delayed signal but quitter
		out >> delay; // feeed the output to the delay
	}
};
```

It's important to not do heavy/costly operation in process function. 

* Changing the filters tunes are expensive, (becuase of calculating complicated float parameters using functions like tan, sin, etc). That's why we use prepare, that runs "once every buffer".
* In DAWs we define "block size" or "buffer size" (e.g. x = 1024, 2048 etc). The DAW will give x samples to the plugin as a single batch to calcualte. The plugin will then give the batch back. (The larger the buffer, the less times they data around and therefore faster computation. However, really big buffer size is bad because it adds latency to the system, because you will have to calculate "buffer size" first to get back a response and start producing the sound ).
* Also, do not do costly operations like allocation in the process function, because it's slow. We always preallocate memory. 


### Reverberation (reverb)

In a real physical space, there are infinate reflections (soundwaves bounce on multiple surfaces to reach our ears). Reverb effect simulates the impulse response of space.
It uses delays to replication the pattern of reflections in real life.

Direct sound, early reflections and reverberation.

How are we going to implement it?
* We could use loads of feedforward delays. But it's too many sounds. (in a cathedral we would like huge amount of them).
* We could use feedback delay. But all the dealys are regularly spaced and you get resonance. (which is not similar to real rooms).
* Therefore, we use a combination of these with spacings.
* we can also add some dampening (a filter in the end to make it duller).


* the best amplifier (you want total harmonic distortion "how much does it distort sounds", the less the better)
* the synthesizers


We use random numbers for parameters (prime numbers that don't even have common factors).

Analogue equipment 
Resonance vs Ringing. (avoid ringing)


* Feeback delay networks (FDNs). Network of feedback delays.
It can be a very good reverb.




### Convolution Reverb

Another approach of making reverb that mimic real spaces is known as convolution reverb.
* we record an 8 second audio sample (e.g. `.wav`) of an impulse and 
* to accomplish that we use a starting pistol or popping ballon or a crazy good speaker to produce an impulse sound in a room
* the recording is essentially "the impulse response" 

* by combining the impulse response and tricks such as FFT (fast fourier transform), we can reproduce the reverb of any sound in that room 
* FFT and reverse FFT move the sound between the time and frequency domains. And calculating a convultion (which is an expensive/slow calculation) in the time domain becomes a simple mutliplication in frequency domain (which is a cheap/fast calculation to execute)
* computers can execute FFT relatively fast and use this method nowadays (40-50 years ago it was impossible). 
* However, artificial reverbs still play a role, because people like experimenting with sounds (they have a different taste).


There are so many reverb plugins in the market (you can pay as much as 500$ for some). In general, it's not really hard to make reverbs. But what is really hard to choosing good presets. It's difficult to tune the dials is difficult for different setting (e.g. a small room or a cathedral, etc). 
These algorithms were kept secret for long time. 
An popular design for reverb is called **Schroeder-Moorer**. It uses an all pass filter by cascading a feedback comb-filter with a feedforward comb-filter. A popular open source reverb is called free-verb ([stanford site](https://ccrma.stanford.edu/~jos/pasp/Freeverb.html)) (open source [github](https://github.com/sinshu/freeverb)).

Good idea for project: it's difficult to create usable smooth dials (e.g. you could have 3 dials, room size, resonance/brightness, echo). 

```cpp
#include <klang.h>
using namespace klang::optimised;

struct MyReverb : Effect {
	Delay<192000> feedforward, feedback;
	LPF filter;

	param times[8] = { 2.078,  5.154,  5.947,  7.544,
		                8.878, 10.422, 13.938, 17.140 }; // in miliseconds
	param gains[8] = {  .609,   .262,  -.3600, -.470, 
		                 .290,  -.423,   .100,   .200 };
	MyReverb() {
		controls = { "Feedback", Dial("Time", 0, 0.5, 0.4), // in seconds
		                         Dial("Gain", 0, 0.4, 0.1),
		                         Dial("Cutoff", 500, 5000, 1500) 
		}; // the controls are only for the feedback (gain, time and cutoff of filter)
		                         
		presets = { { "Bathroom",    { 0.276, 0.057, 3835.062 } },
					{ "Lively Room", { 0.309, 0.060,  806.557 } },
					{ "Air Vent",    { 0.496, 0.089, 2807.678 } },
					{ "Parking Lot", { 0.216, 0.220, 1367.304 } },
		};
	}

	// called once per buffer
	void prepare() {
		filter.set(controls[2]);
	}

	signal early() {
		signal mix = in;
		// feed input to delay
		in >> feedforward;
		// add early reflections
		for (int i = 0; i < 8; i++){
			mix += gains[i] * feedforward( times[i] / 1000 * fs);
		}
		return mix;
	}

	signal late() {
		param time = controls[0];
		param gain = controls[1];
		signal mix = feedback(time*fs*0.0001) * gain;
		return mix >> filter; // the feedback signal
	}

	void process() {
		early() + late() >> out >> feedback;
	}
};
```


```cpp
#include <klang.h>
using namespace klang::optimised;

struct MyReverb : Effect {
	Delay<192000> feedforward, feedback;
	LPF filter;

	param times[8] = { 2.078,  5.154,  5.947,  7.544,
		                8.878, 10.422, 13.938, 17.140 }; // in miliseconds
	param gains[8] = {  .609,   .262,  -.3600, -.470, 
		                 .290,  -.423,   .100,   .200 };
	MyReverb() {
		controls = { "Feedback", Dial("Time", 0, 0.5, 0.4), // in seconds
		                         Dial("Gain", 0, 0.4, 0.1),
		                         Dial("Cutoff", 500, 5000, 1500) 
		};
		                         
		presets = { { "Bathroom",    { 0.276, 0.057, 3835.062 } },
					{ "Lively Room", { 0.309, 0.060,  806.557 } },
					{ "Air Vent",    { 0.496, 0.089, 2807.678 } },
					{ "Parking Lot", { 0.216, 0.220, 1367.304 } },
		};
	}

	// called once per buffer
	void prepare() {
		filter.set(controls[2]);
	}

	signal early() {
		signal mix = in;
		// feed input to delay
		in >> feedforward;
		// add early reflections
		for (int i = 0; i < 8; i++){
			mix += gains[i] * feedforward( times[i] / 1000 * fs);
		}
		return mix;
	}

	signal late() {
		param times[3] = { 0.2, 0.324, 0.777 }; // seconds, (random numbers)
		param gains[3] = { 1.0, 0.6, 0.2 };
		param time_c = controls[0];
		param gain_c = controls[1];
		signal mix = 0;
		for (int i = 0; i < 3; i++){
			mix += feedback( time_c*times[i] * fs) * gain_c*gains[i];
		}
		return mix >> filter; // the feedback signal
	}

	void process() {
		early() + late() >> out >> feedback;
	}
};
```

Use bypass to actually understand the difference between the reverb and the original sound. Also, use the tool to check the impulse response.

If time is really high, we need more taps (for the forward signal)
* TODO: think about this
* TODO: make a control for the amount of taps (the tap times should be random and prime numbers to avoid resonance that leads to ringy sound)

The reverb is one of the holy grails in DSP design.


### Questions / Todos / Ideas

* TODO: make a fast way to compute FFTs and convolutional filters (computers can do this now)
* TODO: use AI for parameter tuning of reverb to create decent plugins that mimic real reverbs

## Lesson 03 - Filters

General notes:
* Filters are used to remove frequency content from a signal.
* The plot shows the spectrum of a signal processed with a low-pass filter (LPF). The filter attenuates or removes a range (band) of frequencies, shown faded.
* The cutoff marks the limit of the pass band (frequencies allowed through the filter), and beginning of the transition into the stop band (where frequencies are fully rejected). (usually it's not just a straight line down)
* slope : dB / octave ("higher-order" filters have steeper slopes for)
* Some filter designs â€” especially in synthesis â€” exhibit resonance



Resonance (Q)
* the sharpness of the spike


In EQ, we want to correct the sound.
* Ducking / Boosting different frequencies

* low-pass (high-cut) filter
* high-pass (low-cut) filter
* band-pass filter (center frequency and bandwidth) (cuttoff vs b)
* band-reject filter (or band-cut filter) (notch filter)

> Analog filters do not have 


For a low pass filter, we want to smooth it out -> moving average
* it is based in previous values, so they affect frequency but also add phase (move the wave to the right)
* it's a frequency depended delay (this phase can call )


* there is also an all-pass filter (it only adds a delay)
 	* decoralte tails, and they are the basis of phasers
	* TODO: code all-pass filters

* z-1 means delay by one in block diagrams (z for zahlen: to count in German)

#### FIR vs IIR

filters are made with math
* finite-impulse response (FIR)
* each time we add a dealy, we increase a delay

* the following is a 3rd order filter:
$$y(n) = 1/3 * x(n) + 1/3 * x(n-1) + 1/3 * x(n-2)$$

* you can add bigger or smaller factors  at the end

* infinite-response filter (IIR) (feedback loop)

* constants a,b to control how much
* this filter would explode if b > 1
* there is recursion, the formula would be:
$$y(n) = a*x(n) + b*y(n)$$
* usally $b = 1 - a$
* the phase moves logarithmically



impulse: more directly related to a delay


* it refers to the single input line

* out at the initial moment is one

```cpp
param a = controls[0]
param b = 1-a
a*in + b*out >> out;
```

* we don't want a linear slider (the interesting range is actually when a ~ 0.01 - 0.10 )
* frequency we perceive logarithmically
* the higher b, the higher the effect of the past (and lower the present note)
* the higher a (the lower b), the higher the effect of the new input (and lower the past) 

```cpp
// squaring/cubing a control can make it better
param a = controls[0]
a = a*a
param b = 1-a
a*in + b*out >> out;
```

```cpp
#include <klang.h>
using namespace klang::optimised;

struct MyIIR : Effect {
	signal last = 0; // last output

	MyIIR() {
		controls = { 
			Dial("a"),
		};
	}

	void process() {
		param a = controls[0];
		a = a*a; // to make slider more usable
		// warpping (bending): cubbing or squarring the slider (it's works when we are between 0 and 1)
		param b = 1-a;
		a*in + b*last >> out;
		out >> last;
	}
};
```



> We can minus the lower frequencies we produced to only keep the high frequencies. And that how we produce a high pass filter. !! AMAZING !!

```cpp
#include <klang.h>
using namespace klang::optimised;

struct MyIIR : Effect {
	signal last = 0; // last output

	MyIIR() {
		controls = { 
			Dial("a"),
		};
	}

	void process() {
		param a = controls[0];
		a = a*a; // to make slider more usable
		param b = 1-a;
		signal lpf = a*in + b*last;
		last << lpf;

		singal hpf = in - lpf;
		hpf >> in;
	}
};
```

It's very hard to make filters.
Relatively few DSP engineer understand how they work.


In alaogue systems, you use capacitors and resistances. Trying to fake analogue (non linear stuff).

That frequncy get boosted. It's a desirable effect.


#### biquad filter

this has FIR and IIR.
the 5 coefficients can create anything (lowpass, highpass, bandpass).

RBJ biquad filters

* [klang makes it](https://github.com/nashaudio/klang/blob/f1f9b6e7896345664537eabaa03be0e075371420/klang.h#L4578)

* it has code so you map the slider with Hz.
* you can warp it.

We are going to be using it as a black box.



> White noise is a singal generation. Random numbers from 0 to 1.


Mapping values.

We are listening to cut sounds.
We want to smoothen the cutoff. (we add a filter essentially)


* Dials update 30 times a second
* process() executes 44000 times a second

> Rule of Thumb: 100ms latency feels instant to humans


doubling the filter (makes the slope more steep)
* each one will distort the phase
* treble and bass (if you link them up to be inverse)




dynamic level compressors 
* first we had limiters (automatic way to stop too loud signals)
* a compressor does this artificially
* a bit like distortion but they work onlevel

* on mixing desks with 
* you can do it with voice, 
* gritty, heavy sound, compreses

* multi-band processing (making)
* bass boost
* exciter (harmonic enahncer)
* eq (31 band equalisers)
	* the transition bands should sum up to 1

* let's make an eq version of the dj console
	* first design costs to phases
	* second approach: low-pass, high-pass and mid is subraction of them.

> each time you pass the signal, you get the cost of one phase. For FIR you have predictable phase. But with IIR, it's unpredictable (the price you pay for efficiency).

### More Qs:

* do you have any courses on signals? in YT? There is that guy who is really good.
* how can I make a compressor? TODO

* encapsulation: hide the internals, and don't allow them change the inside (python has it by convention)
* RTFM: read the fucking manual


## Lesson 02 - Distortion

* Distortion describes any process that changes (distorts) the shape of the waveform.
* The pitch (effectively the frequency and wavelenght) do not change.
* Gain is a linear effect, meaning it doesn't change the shape of the wave â€” only its scale.

As long as gain is constant or slow changing (as with tremolo - pictured), the wave shape
(and tonal quality, or timbre) doesn't change â€” it simply becomes louder or quieter. However, abrupt or more rapid changes alter â€” or distort â€” the wave shape; changing its timbre with amplitude and ring modulation. Such non-linear processes add harmonically related spectral content to the original signal, called harmonic distortion.


FM : important in synthesis
Analogue systems are inherently non-linear (amps, mics, pick-ups, speakers, analog synths). Every copy/transmition you make is distorted. But it might be perceived as "warmth" or "has character". 

Distortion can also be used as a creative effect intentionally â€” commonly used in guitar pedals (fuzz, overdrive), synths (bitcrushing - below), and production (exciters, saturation aka adding harmonics). 
In DSP, we can model distortions and non-linear processes using functions to manipulate amplitude.

Everybody uses mpeg (mp3) and stream which are worse than CDs. Mp3 is compressed (it throws away all the content we cannot hear).

> `.wav` or `.aif` are CD quality like. When you are at the studio, always use these and at the end convert to `.mp3` (mpeg is compressed and mono, information is lost essentially).

* [saturation explained](https://youtu.be/YuojAtE8YCY). people use other words for saturation that fall under this umbrella term: saturation, drive, overdrive, fuzz, warmth, grit.

clipping : gain with limit at (-1, 1). if you apply a lot of it, effectively you create a squarewave. (the basic waves are sinewave, squarewave, sawwave). Clipping is a classic type of distortion. it creaets edges in the sinewave.

```cpp
// Clipping.k
#include <klang.h>
using namespace klang::optimised;

struct Clipping : Effect {

	// Initialise plugin (called once at startup)
	Clipping() {
		controls = { 
			Dial("Clipping", 0.0, 20.0, 1.0),
		};
	}

	// Apply processing (called once per sample)
	void process() {
		param gain = controls[0];
		max(-1.0f, min(1.0f, in*gain)) >> out;
	}
};
```

We can represent distortions as a transfer function that maps input amplitude (x-axis) to output (y-axis). `y = x`, known as the identity (no change). `y = 0.5x` would give gain by half. `y= 2x` would make the amplitude go away.

In order to push the audio signal outside of bounds in order to be clipped, we have to put gain (amplitude). in the clipping scenario, gain is called `overdrive` (beacause it makes signal go over the boundries).

`clipping` is great with drums.

```cpp
#include <klang.h>
using namespace klang::optimised;

signal clip(signal x){
	signal out;
	if (x > 1)
		out = 1;
	else if (x < -1)
		out = -1;
	else
		out = x;
	return out;
}
	
struct Clipping : Effect {
	Clipping() {
		controls = { 
			Dial("Overdrive", 1, 11, 1),  // controls how much of input goes `over` the threshold
			Dial("Output Gain", 0, 1, 1) // it's really loud, maybe you want to make it quieter
		};
	}

	void process() {
		signal in_gain = controls[0];
		signal out_gain = controls[1];
		
		out_gain * clip(in*in_gain) >> out;
		
		clip >> graph(-2,2);
	}
};
```

> Even if a violin and a piano play the same note, it sounds different (although similar pitch). it's a different vibe. in music we say different 'timbre'.

squarewave is richer in terms of harmonics. (TODO: listen to the difference between square and sine).

What are harmonics? frequencies that are related to each other (multiples of the base). this is how we perceive music and pitch.

sinewave = contain only the first harmonic aka the fundamental, e.g. (1)
sawwave = contains the first harmonic and all multipes of it (with decreasing amplitudes), e.g. (1,2,3,4,5,6, ...) or (2,4,6,8,10, ...)
squarewave = contains the first harmonic and all the odd multiple of it (with decreasing amplitudes), (1,3,5, ...) or (2, 6, 10, ...)

* A sinewave with crazy overdrive becomes a squarewave essentially.
* if you double the fundamental, that is an octave higher.

In order to produce even harmonics, the transfer function needs to be assymetric (clipping positive values at one threshold and negative values at another threshold).

```cpp
#include <klang.h>
using namespace klang::optimised;

signal assymetric_clip(signal x){
	signal out;
	if (x > 1)
		out = 1;
	else if (x < -0.5)
		out = -0.5;
	else
		out = x;
	return out;
}
	
struct Clipping : Effect {
	Clipping() {
		controls = { 
			Dial("Overdrive", 1, 11, 1),  // controls how much of input goes `over` the threshold
			Dial("Output Gain", 0, 1, 1) // it's really loud, maybe you want to make it quieter
		};
	}

	void process() {
		signal in_gain = controls[0];
		signal out_gain = controls[1];
		
		out_gain * assymetric_clip(in*in_gain) >> out; // this produces even harmonics
        // it also produces a DC offset,
		
		clip >> graph(-2,2);
	}
};

```


Hard clipping is a harsh effect, most similar to "fuzz" style guitar distortion pedals.
In soft clipping, we smooth the transition into clipping, more like "overdrive" pedals.
Soft clipping affects all amplitudes; it is a curve, so entirely non-linear, therefore will distort the sound with or without overdrive.


we can stretch vertically and horizontally (by mulitplication) and moving around a function (by adding). [desmos](https://www.desmos.com/calculator) is a great online tool to visualise all of these. using mathematical functions to manipulate the amplitudes of the signal is called shaping.


```cpp
#include <klang.h>
using namespace klang::optimised;

signal softclip1(signal x, param c){
    if (x >= 0){
        return (1+c) * x / (1 + c*x)
    }
    return (1+c) * x / (1 - c*x)
}

signal softclip2(signal x, param c){
    // sigmoid: behaves similarly to a soft compressor, smoothly limiting the peaks.
    return x / sqrt(1 + x*x);
}


struct Shaping : Effect {
	Shaping() {
		controls = { 
			Dial("c", 0, 9)
		};
	}

	void process() {
		param c = controls[0];
		softclip1(in, c) >> out;
	}
};
```

In Klang, `param` means controller vs `signal` which refers to audio.
MaxMSP and RNBO are some classic software applications for manipulating sounds.

you can have multiple distortions. instead of switch, you can use cross-fade between two signals (linear combination between two distorted singals).


other distortions: foldback, bitcrushing (quantizing/rounding in discrete levels/steps, daft punk used it a lot)

```cpp
#include <klang.h>
using namespace klang::optimised;

signal bitcrush(signal x, param c){ 
    int levels = int(c); // quantization levels (if really big, it's indistinguishable from original signal) 
    param level_inc = 1.0 / (2*levels); // increment per level 
    // [0, level_inc], [1*level_inc, 3*level_inc], [3*level_inc, 5*level_inc], ..., [1-3*level_inc, 1-level_inc] [1-level_inc, 1]
    // essentially rounding each x to the closest level
    int group = 0;
    if (x > 0){
    	group = (int(x / level_inc) + 1) / 2;
    }
    else {
    	group = (int(x / level_inc) - 1) / 2;
    }
    return group * 2 * level_inc;
}

signal bitcrush5(signal x){
	return bitcrush(x, 5.0);
}

struct MyEffect : Effect {
	MyEffect() {
		controls = { 
			Dial("c", 1, 10, 5)
		};
	}

	void process() {
		param c = controls[0];
		bitcrush5 >> graph(-1.05,1.05);
		bitcrush(in, c) >> out;
	}
};

```


threshold for pain for human ears: 120dB (you can actually hear these frequencies in shitty festibvals)

vertical resolution: (amount of horizontal lines, amplitudes that we can have):
* the standard now is 16-bit
* 8-bit was an old thing with character
* 12-bit were used by earlier samplers
* 14-bit was a thing
* 16-bit became a standard 1 year after CDs were invented 

doubling the dynamic range is equivelant to 6 decibels increase.

some books:
* Psychoacoustic: auditory analysis
* David Chris: audio processes book

TODO: hunt some transfer functions


### symmetry and harmonics

Symmetry vs. Harmonics
Hi George,

I've tried to find an accessible explanation for why only odd harmonics are produced by symmetric transfer functions, but there's not much that doesn't require an understanding of Fourier theorem (which can be used to transform a time domain signal into the frequency domain, and thus find which frequencies exist in a signal - e.g. FFT, which stands for Fast Fourier Transform and allows us to plot spectrums and sonograms). We'll touch a little on Fourier in Additive Synthesis, but without going into the maths in detail.

I gave ChatGPT a crack at summarising it, which I've included below. It provides a little more context, but still needs to you understand Fourier. In practice, for now, you really only need to know the take homes (symmetric = odd harmonics, assymetric = both).

Hope this helps!

Best,
Chris

"Symmetrical transfer functions produce only odd harmonics because of their inherent mathematical properties. A transfer function is symmetrical when f(âˆ’x)=âˆ’f(x), meaning it is odd with respect to the origin. When a sinusoidal input passes through such a function, the resulting waveform contains only odd powers of the input signal in its expansion (e.g. x, x ^ 3, x ^ 5, etc.). These odd powers correspond to odd harmonics in the Fourier series.

To produce even harmonics, the transfer function must have an asymmetric component. Asymmetric functions include terms that are even powers of the input (e.g. x ^ 2, x ^ 4, etc.), which correspond to even harmonics in the output. Asymmetry introduces this even-order nonlinearity, breaking the symmetry condition f(âˆ’x)=âˆ’f(x), and allowing the creation of both odd and even harmonic content.

In summary:

Symmetrical transfer functions (odd functions): Produce only odd harmonics.
Asymmetric transfer functions (even + odd terms): Produce both even and odd harmonics."

## Lesson 01 - DSP Basics

Sound in a digital form is just a sequence of numbers (that express the amplitutde at a given point in time).

A basic workflow of how sound gets captured, saved, manipulated and reproduced is as follows:
* the microphone is a device that captures sound (changes in the air) and turns them into voltage changes.
* the ADC (analog to digital converter) transforms voltages to digital numbers.
* using DAWs and other computer programs (e.g. plugings), we can manipulate the digital signals and do all sorts of stuff.
* the DAC (digital to analog converter) transforms digital numbers to voltages. The sound card we connect to our laptop acts essentially as an ADC and DAC.
* lastly, the amplifier increases the power of an analogue signal and the speaker projects the enhanced sound. 

[Klang](https://github.com/nashaudio/klang) is a C++ library that makes it easy to create plugins using C++. Audio programming needs to be low latency, hence C++ is great for that. Klang offers predefined objects (like Filters, Oscillators) and syntactic sugar (`signal`, `>>` and `<<` operators) that make readable code. Using the [Klang Studio](https://nash.audio/klang/studio/) as a plugin, you can write code inside the DAW and test it. Amazing stuff!

It's valuable as a musician to understand what the fundamental effects (like filtering, tremolo) do numerically and create an intuition of how different sounds are created.




```cpp
// Gain.klang

#include <klang.h>
using namespace klang::optimised;

struct Gain : Effect {

	Gain() { 
		controls = { 
			Dial("Gain") 
		};
	}

	void process() { 
		param gain = controls[0];
		gain >> debug;
		in * gain >> out;
	}

};
```

Some terminology on gain:
* Gain is essentially scaling the level/amplitude of all the samples. 
* It's equivelant to mulitplication (*).
* Scaling by gain=0.0 **mutes** the signal. Scaling by gain=1.0 leaves it **unchanged**.
* Scaling by 0.0 < gain < 1.0 **attenuates** the signal (moves it towards/closer to the x-axis).
* Scaling by gain > 1.0 **amplifies** the signal (moves it away from the x-axis).

A standard way to represent audio processes are block diagrams. Getting familiar with them is crucial. 

Some terminology on mixing:
* Mixing is essentially combining the amplitudes/levels of the corresponding samples of two or more singals.
* It's equivelant to addition (+). 
* Because the amplitudes can be positive or negative, they may **constructively or destructively interfere** with each other
* The addition of these two simple signals creates a more complex wave. How sound waves interfere depends on their frequencies and amplitudes.
* When two signals have the same frequency, we say they are **in-phase** when they go up/down on the same times and interfere constructively. E.g. mixing identical, in-phase signals yields double the amplitude.
* When two signals have the same frequency, we say they are **out-of-phase** when they go up/down on the opposite times and interfere destructively. E.g. mixing identical, out-of-phase singals yields a mute signal (they cancel each other out).

The mono sigal is made out of only one signal, whereas the stereo signal consists of two signals that are played simulateanously, one for the left speaker and one for the right speaker (it is reacher in sound and we can create effects like pan).

To mix a stereo signal down to a mono mix, we add the left and right signals (`(in.l + in.r)*0.5 >> out`).


```cpp


// Pan.klang
#include <klang.h>
using namespace klang::optimised;

struct Pan : Stereo::Effect {
	Pan() { 
		controls = { 
			Dial("Pan") 
		};
	}

	void process() { 
		param pan = controls[0];
		signal mono = 0.5 * (in.l + in.r);
		(1 - pan) * mono >> out.l;
		pan * mono >> out.r;
	}

};

// there is an issue with 0.5 pan having half the amplitude as the initial signal (volume drop)
// "Equal power panning law": is when panning doesn't lose it's volume.
// There is also -3dB, -4.5dB -6dB, depending on the volume lost.
// https://en.wikipedia.org/wiki/Panning_law

// MyEffect.klang : saw with filter

#include <klang.h>
using namespace klang::optimised;

struct MyEffect : Effect {
	Saw osc;    // (sawtooth oscillator)
	LPF filter; // (low-pass filter)

	MyEffect() { 
		controls = { 
			Dial("Cutoff", 100, 1000, 440) // min, max, start
		};
		osc.set(440); // set to 440Hz
	}

	void process() {
		param f = controls[0];
		filter.set(f);
		osc >> filter >> out;
	}
};
```

Tremolo is the effect of rapid modulation (using an LFO) of the gain of signal.

```cpp
// Tremolo.klang
// an oscillator is essentially a signal (saw, sine, ...)
// a lfo is low frequency oscillator (signal with f = 1 - 10Hz)
// tremolo is a signal where the amplitude is modulated by an LFO 
// (essentially an oscillator that slowly increases/decreases the gain)

#include <klang.h>
using namespace klang::optimised;

struct Tremolo : Effect {
	Sine lfo;

	// Initialise plugin (called once at startup)
	Tremolo() {
		controls = { 
			Dial("Mod Rate", 1.0, 10.0, 6.0),
			Dial("Mod Depth", 0.0, 0.5, 0.5),
		};
	}

	// Prepare for processing (called once per buffer)
	void prepare() {
		
	}

	// Apply processing (called once per sample)
	void process() {
		param rate = controls[0];
		param depth = controls[1];
		
		// different types of modulation
		// signal mod = lfo(rate); // lfo osc between [-1, 1]
		// signal mod = lfo(rate) * depth; // lfo osc between [-depth, +depth] ( [-0.5, 0.5] for depth = 0.5 )
		// signal mod = lfo(rate) * depth + 0.5; // lfo osc between [0.5-depth, 0.5+depth] ( [0, 1] for depth = 0.5, [0.5,0.5] for depth = 0.5 )
		signal mod = lfo(rate) * depth + (1-depth); // lfo osc between [1-2*depth, 1] ( [0, 1] for depth = 0.5, [1,1] for depth = 1 )
		mod >> debug;
		in * mod >> out;
	}
};
```

The ring mod effect is similar to tremolo, famously used for the Dalek voice in Doctor
Who ([example video](https://youtu.be/qUL0xwEbkJs)). It often creates metallic or bell-like sounds (a bit inharmonic). Essentially two signals (not necessarily LFO and original signal) are mutliplied together to create a more complex signal. To adapt our tremolo / AM effect to be a ring mod, simply remove the scaling and offset factors in the mod signal.

In the professional community, the industry standard framework for developing plugins is [Juce](https://juce.com/). Juce is used by Traction, maxMSP, FocusRight, etc. Every year during November there is a [ADC (audio developer conference)](https://audio.dev/), and it's the number 1 networking opportunity. In 2025 it takes place in Bristol. 

Why is 44.1kHz (44,100 Hz) the standard sampling frequency? Explanation in [wiki](https://en.wikipedia.org/wiki/44,100_Hz). In brief, the Nyquistâ€“Shannon sampling theorem says the sampling frequency must be greater than twice the maximum frequency one wishes to reproduce. To capture the human hearing range of roughly 20 Hz to 20,000 Hz, the sampling rate had to be greater than 40 kHz. Furthermore, the ideal filter is practically impossible to implement, so in practice a transition band is necessary, where frequencies are partly attenuated (reduced in force). The wider this transition band is, the easier and more economical. The 44.1 kHz sampling frequency allows for a 2.05 kHz transition band.

## Lessons overview

* Lesson 01: Intro - DSP Basics
* Lesson 02: Effects - Distortion
* Lesson 03: Effects - EQ
* Lesson 04: Effects - Delay
* Lesson 05: Effects - Flanger
* Lesson 06: Synthesis - Additive
* Lesson 07: Synthesis - Subtractive
* Lesson 08: Synthesis - AM & FM
* Lesson 09: Synthesis - Physical Modeling
* Lesson 10: Outro - Plugin Project

